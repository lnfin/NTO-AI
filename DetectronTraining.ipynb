{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CYLPQYI0YKjR","executionInfo":{"status":"ok","timestamp":1646355684535,"user_tz":-180,"elapsed":181593,"user":{"displayName":"Максим Кирилюк","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiZlomAsRWc2ZvwiL0cRS2Nsnyf8tkYmWd5rrd_w=s64","userId":"05409930939227430098"}},"outputId":"3f8cfb57-95aa-4570-a726-749fc46b5378"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n","/content/drive/MyDrive/DataScience/Practice/НТИ/ИИ2021/FINAL\n","\u001b[K     |████████████████████████████████| 708.0 MB 9.3 kB/s \n","\u001b[K     |████████████████████████████████| 5.9 MB 18.2 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.6.0+cu101 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.6.0+cu101 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 5.6 MB 2.9 MB/s \n","\u001b[K     |████████████████████████████████| 47 kB 1.8 MB/s \n","\u001b[K     |████████████████████████████████| 74 kB 2.9 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 53.4 MB/s \n","\u001b[K     |████████████████████████████████| 112 kB 48.2 MB/s \n","\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 421.8 MB 16 kB/s \n","\u001b[K     |████████████████████████████████| 3.8 MB 13.2 MB/s \n","\u001b[K     |████████████████████████████████| 448 kB 48.3 MB/s \n","\u001b[K     |████████████████████████████████| 50 kB 6.3 MB/s \n","\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n","Зависимости установлены\n"]}],"source":["#@title 1. Установка зависимостей\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd '/content/drive/MyDrive/DataScience/Practice/НТИ/ИИ2021/FINAL'\n","\n","!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html -q\n","!python -m pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html -q\n","!pip install tensorflow==2.1.0 -q\n","!pip install opencv-python -q\n","\n","import cv2\n","import random\n","import json\n","import os\n","import copy\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.filterwarnings(\"ignore\")\n","import ipywidgets as widgets\n","from ipywidgets import interact, interact_manual\n","import shutil\n","\n","import tqdm\n","from matplotlib import pyplot as plt\n","import numpy as np\n","\n","import torch, torchvision\n","import detectron2\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog\n","from detectron2.data.datasets import register_coco_instances, load_coco_json\n","from detectron2.data import detection_utils as utils\n","from detectron2.engine import DefaultTrainer\n","from detectron2.engine import HookBase\n","\n","import logging\n","logger = logging.getLogger('detectron2')\n","logger.setLevel(logging.CRITICAL)\n","\n","print('Зависимости установлены')"]},{"cell_type":"markdown","metadata":{"id":"ff6OunIpYKjl"},"source":["## 2. Регистрация датасета"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8LB8rrXQJjH","executionInfo":{"status":"ok","timestamp":1646355684950,"user_tz":-180,"elapsed":419,"user":{"displayName":"Максим Кирилюк","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiZlomAsRWc2ZvwiL0cRS2Nsnyf8tkYmWd5rrd_w=s64","userId":"05409930939227430098"}},"outputId":"9c1db2dc-5fa9-462e-8131-0c2f206c40b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["binary.npz  checkpoints  images  test_pred.npz\n"]}],"source":["!ls data/train_segmentation/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AWcfvpyFYKjl","executionInfo":{"status":"ok","timestamp":1646355695931,"user_tz":-180,"elapsed":10983,"user":{"displayName":"Максим Кирилюк","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiZlomAsRWc2ZvwiL0cRS2Nsnyf8tkYmWd5rrd_w=s64","userId":"05409930939227430098"}},"outputId":"bc2e7a8b-83e1-4405-dba8-5daf6de75185"},"outputs":[{"output_type":"stream","name":"stdout","text":["Размер обучающей выборки (Картинки): 854\n","Размер обучающей выборки (Картинки): 81\n","Размер тестовой выборки (Картинки): 78\n"]}],"source":["with open('data/annotations_train.json') as f:\n","    annotations_train = json.load(f)\n","with open('data/annotations_val.json') as f:\n","    annotations_val = json.load(f)\n","# with open('data/infin/annotations.json') as f:\n","#     annotations_infin = json.load(f)\n","# with open('train_segmentation/annotations_test.json') as f:\n","#     annotations_val = json.load(f)\n","    \n","for d in ['train','val']:\n","    DatasetCatalog.register(f\"my_dataset_{d}\", lambda d=d: load_coco_json((f\"data/annotations_{d}.json\"),\n","    image_root= \"data/train_segmentation/images\",\n","    dataset_name=f\"my_dataset_{d}\",\n","    extra_annotation_keys=['bbox_mode']))\n","    \n","DatasetCatalog.register(f\"infin_train\",lambda d=d: load_coco_json((f\"data/infin/images/annotations_infin.json\"),\n","image_root= \"data/infin/images/annotated\",\n","dataset_name=f\"infin_train\",\n","extra_annotation_keys=['bbox_mode']))\n","\n","dataset_dicts_infin_train = DatasetCatalog.get(\"infin_train\")\n","infin_train_metadata = MetadataCatalog.get(\"infin_train\")\n","\n","dataset_dicts_train = DatasetCatalog.get(\"my_dataset_train\")\n","train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n","\n","dataset_dicts_val = DatasetCatalog.get(\"my_dataset_val\")\n","val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n","\n","print('Размер обучающей выборки (Картинки): {}'.format(len(dataset_dicts_train)))\n","print('Размер обучающей выборки (Картинки): {}'.format(len(dataset_dicts_infin_train)))\n","print('Размер тестовой выборки (Картинки): {}'.format(len(dataset_dicts_val)))"]},{"cell_type":"markdown","metadata":{"id":"ngxxU09LYKjp"},"source":["##   3 Обучение модели\n","[о конфиге](https://detectron2.readthedocs.io/en/latest/modules/config.html)\n","[о лоссах](https://stackoverflow.com/questions/70169219/what-is-total-loss-loss-cls-etc)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yN3oflOIkSIu"},"outputs":[],"source":["#@markdown imports\n","from detectron2.data import build_detection_train_loader, build_detection_test_loader\n","from detectron2.data import detection_utils as utils\n","from detectron2.data import transforms as T\n","from detectron2.engine import DefaultPredictor\n","from detectron2.engine import DefaultTrainer\n","from detectron2.engine import HookBase\n","from submit.segmentation.transforms import RescaleImage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Fdy2AKz5Xhu"},"outputs":[],"source":["#@markdown Transforms and Augmentations\n","from PIL import Image\n","from detectron2.data import transforms as T\n","\n","\n","class RescaleImage(T.Augmentation):\n","    def __init__(self, output_height, interp=Image.BILINEAR):\n","        super().__init__()\n","        self.output_height = output_height\n","        self.interp = interp\n","\n","    def get_transform(self, image):\n","        h, w = image.shape[:2]\n","        new_width = int(w * (self.output_height / h))\n","        return T.ResizeTransform(h, w, self.output_height, new_width, self.interp)\n","\n","class RandomResize(T.Augmentation):\n","    def __init__(self, koef1=0.9, koef2=1.1, interp=Image.BILINEAR):\n","        super().__init__()\n","        self.koef1 = koef1\n","        self.koef2 = koef2\n","        self.interp = interp\n","\n","    def get_transform(self, image):\n","        h, w = image.shape[:2]\n","        new_width = int(w * random.uniform(self.koef1, self.koef2))\n","        new_height = int(h * random.uniform(self.koef1, self.koef2))\n","        return T.ResizeTransform(h, w, new_height, new_width, self.interp)\n","\n","class DenoisingTransform(T.Transform):\n","    def __init__(self, h: int = 3, hColor: int = 3, \n","                    templateWindowSize: int = 7, searchWindowSize: int = 21):\n","        super().__init__()\n","        self._set_attributes(locals())\n","\n","    def apply_image(self, img: np.ndarray) -> np.ndarray:\n","        return cv2.fastNlMeansDenoisingColored(img, self.h, self.hColor,\n","                                        self.templateWindowSize, self.searchWindowSize)\n","    def apply_coords(self, coords: np.ndarray) -> np.ndarray:\n","        return coords\n","\n","    def apply_segmentation(self, segmentation: np.ndarray) -> np.ndarray:\n","        return segmentation\n","\n","    def inverse(self) -> T.Transform:\n","        return T.NoOpTransform()\n","    \n","class Denoise(T.Augmentation):\n","    def __init__(self, h: int = 3, hColor: int = 3, \n","                    templateWindowSize: int = 7, searchWindowSize: int = 21):\n","        super().__init__()\n","        self._init(locals())\n","    \n","    def get_transform(self, image):\n","        return DenoisingTransform(self.h, self.hColor,\n","                                    self.templateWindowSize, self.searchWindowSize)\n","    \n","class BinarizationTransform(T.Transform):\n","    def __init__(self, block_size: int = 7, c: int = 3):\n","        super().__init__()\n","        self._set_attributes(locals())\n","\n","    def apply_image(self, img: np.ndarray) -> np.ndarray:\n","        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","        binary = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, self.block_size, self.c)\n","        binary = np.array([binary, binary, binary])\n","        binary = binary.transpose(1, 2, 0)\n","        return binary\n","\n","    def apply_coords(self, coords: np.ndarray) -> np.ndarray:\n","        return coords\n","\n","    def apply_segmentation(self, segmentation: np.ndarray) -> np.ndarray:\n","        return segmentation\n","\n","    def inverse(self) -> T.Transform:\n","        return T.NoOpTransform()\n","\n","\n","class Binarization(T.Augmentation):\n","    def __init__(self, block_size: int = 7, c: int = 3):\n","        super().__init__()\n","        self._init(locals())\n","    \n","    def get_transform(self, image):\n","        return BinarizationTransform(self.block_size, self.c)\n","\n","\n","class ThinningTransform(T.Transform):\n","    def __init__(self, k: int = 3, iterations: int = 1):\n","        assert k % 2 == 1, \"k should be odd\"\n","        super().__init__()\n","        self._set_attributes(locals())\n","\n","    def apply_image(self, img: np.ndarray) -> np.ndarray:\n","        img = img[:, :, 0]\n","        img = np.array([img]).transpose(1, 2, 0)\n","        print(img.shape, np.unique(img))\n","        kernel = np.ones((self.k, self.k), np.uint8)\n","        erosion = cv2.erode(img, kernel, iterations=self.iterations)\n","        erosion = np.array([erosion, erosion, erosion])\n","        erosion = erosion.transpose(1, 2, 0)\n","        return erosion\n","\n","    def apply_coords(self, coords: np.ndarray) -> np.ndarray:\n","        return coords\n","\n","    def apply_segmentation(self, segmentation: np.ndarray) -> np.ndarray:\n","        return segmentation\n","\n","    def inverse(self) -> T.Transform:\n","        return T.NoOpTransform()\n","\n","\n","class Thinning(T.Augmentation):\n","    def __init__(self, k: int = 3, iterations: int = 3):\n","        super().__init__()\n","        self._init(locals())\n","    \n","    def get_transform(self, image):\n","        return ThinningTransform(self.k, self.iterations)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iv3rIFaOkQ_2"},"outputs":[],"source":["def get_train_transform_list(size: int, crop_size: float):\n","    train_transform_list = [\n","        RandomResize(0.85, 1.15),\n","        RescaleImage(size),\n","        T.RandomCrop('absolute', (int(size * crop_size), int(size * crop_size))),\n","        T.RandomContrast(0.9, 1.1),\n","        T.RandomBrightness(0.9, 1.1),\n","        T.RandomSaturation(0.9, 1.1),\n","        # Binarization(7, 3),\n","    ]\n","    return train_transform_list\n","def get_test_transform_list(size: int):\n","    test_transform_list = [\n","        RescaleImage(size),\n","        # Binarization(7, 3),\n","        # Thinning(3, 1),\n","        # Denoise(5, 5, 7, 21)\n","    ]\n","    return test_transform_list"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"4-mZJtFOJCR2"},"outputs":[],"source":["#@markdown LossEvalHook\n","from detectron2.engine.hooks import HookBase\n","from detectron2.evaluation import inference_context\n","from detectron2.utils.logger import log_every_n_seconds\n","from detectron2.data import DatasetMapper, build_detection_test_loader\n","import detectron2.utils.comm as comm\n","import torch\n","import time\n","import datetime\n","\n","class LossEvalHook(HookBase):\n","    def __init__(self, eval_period, model, data_loader):\n","        self._model = model\n","        self._period = eval_period\n","        self._data_loader = data_loader\n","    \n","    def _do_loss_eval(self):\n","        # Copying inference_on_dataset from evaluator.py\n","        total = len(self._data_loader)\n","        num_warmup = min(5, total - 1)\n","            \n","        start_time = time.perf_counter()\n","        total_compute_time = 0\n","        losses = []\n","        for idx, inputs in enumerate(self._data_loader):            \n","            if idx == num_warmup:\n","                start_time = time.perf_counter()\n","                total_compute_time = 0\n","            start_compute_time = time.perf_counter()\n","            if torch.cuda.is_available():\n","                torch.cuda.synchronize()\n","            total_compute_time += time.perf_counter() - start_compute_time\n","            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n","            seconds_per_img = total_compute_time / iters_after_start\n","            if idx >= num_warmup * 2 or seconds_per_img > 5:\n","                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n","                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n","                log_every_n_seconds(\n","                    logging.INFO,\n","                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n","                        idx + 1, total, seconds_per_img, str(eta)\n","                    ),\n","                    n=5,\n","                )\n","            loss_batch = self._get_loss(inputs)\n","            losses.append(loss_batch)\n","        mean_loss = np.mean(losses)\n","        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n","        comm.synchronize()\n","\n","        return losses\n","            \n","    def _get_loss(self, data):\n","        # How loss is calculated on train_loop \n","        metrics_dict = self._model(data)\n","        metrics_dict = {\n","            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n","            for k, v in metrics_dict.items()\n","        }\n","        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n","        return total_losses_reduced\n","        \n","        \n","    def after_step(self):\n","        next_iter = self.trainer.iter + 1\n","        is_final = next_iter == self.trainer.max_iter\n","        if is_final or (self._period > 0 and next_iter % self._period == 0):\n","            self._do_loss_eval()\n","        self.trainer.storage.put_scalars(timetest=12)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xQkv0TooYKjq"},"outputs":[],"source":["# MERGE\n","cfg = get_cfg()\n","MODEL_CONFIG_PATH = \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"\n","cfg.merge_from_file(model_zoo.get_config_file(MODEL_CONFIG_PATH)) \n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(MODEL_CONFIG_PATH)\n","\n","\n","# DATA\n","cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n","cfg.DATASETS.TEST = (\"my_dataset_val\",)\n","cfg.DATALOADER.NUM_WORKERS = 4\n","\n","\n","# INPUT\n","cfg.INPUT.FORMAT = 'BGR' \n","cfg.INPUT.RANDOM_FLIP = \"horizontal\"\n","\n","SIZE = 1240\n","cfg.INPUT.MIN_SIZE_TRAIN = SIZE\n","cfg.INPUT.MAX_SIZE_TRAIN = SIZE\n","cfg.INPUT.MIN_SIZE_TEST = SIZE\n","cfg.INPUT.MAX_SIZE_TEST = SIZE\n","train_transform_list = get_train_transform_list(SIZE, 0.65)\n","test_transform_list = get_test_transform_list(SIZE)\n","\n","\n","# MODEL\n","# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25\n","# cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.25\n","cfg.MODEL.RPN.NMS_THRESH = 0.35\n","\n","cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16, 32, 64, 128, 256, 512]]\n","cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.125, 0.25, 0.5, 1.0]]\n","\n","cfg.MODEL.RPN.BBOX_REG_LOSS_WEIGHT = 1.0\n","cfg.MODEL.RPN.LOSS_WEIGHT = 1.0\n","cfg.MODEL.SEM_SEG_HEAD.LOSS_WEIGHT = 1.0\n","\n","# cfg.MODEL.BACKBONE.NAME = \"build_resnet_backbone\"\n","# cfg.MODEL.BACKBONE.FREEZE_AT = 2 # [1, 2, 3, 4, 5]\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n","# cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES = 1\n","\n","\n","cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 12000 * 5\n","cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 2000 * 5\n","\n","\n","# SOLVER\n","cfg.SOLVER.BASE_LR = 0.005\n","cfg.SOLVER.GAMMA = 0.5\n","\n","cfg.SOLVER.MAX_ITER = 6000\n","cfg.SOLVER.STEPS = (5000,)\n","cfg.SOLVER.CHECKPOINT_PERIOD = 1000\n","cfg.SOLVER.IMS_PER_BATCH = 4\n","\n","cfg.TEST.AUG.FLIP = False\n","cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n","# cfg.TEST.EVAL_PERIOD = 500\n","\n","\n","# SAVE\n","NAME = 'my_hope'\n","cfg.OUTPUT_DIR = f'train_segmentation/checkpoints/{NAME}'\n","# shutil.rmtree(cfg.OUTPUT_DIR)\n","if not os.path.exists(cfg.OUTPUT_DIR):\n","    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","f = open(f'train_segmentation/checkpoints/{NAME}/config.yml', 'w')\n","f.write(cfg.dump())\n","f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tm2GS3zCktO3"},"outputs":[],"source":["#@markdown Mappers\n","def train_mapper(dataset_dict):\n","    dataset_dict = copy.deepcopy(dataset_dict)\n","    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n","    image, transforms = T.apply_transform_gens(train_transform_list, image)\n","    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n","    annos = [\n","        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n","        for obj in dataset_dict.pop(\"annotations\")\n","    ]\n","    instances = utils.annotations_to_instances(annos, image.shape[:2])\n","    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n","    return dataset_dict\n","\n","def test_mapper(dataset_dict):\n","    dataset_dict = copy.deepcopy(dataset_dict)\n","    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n","    image, transforms = T.apply_transform_gens(test_transform_list, image)\n","    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n","    annos = [\n","        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n","        for obj in dataset_dict.pop(\"annotations\")\n","    ]\n","    instances = utils.annotations_to_instances(annos, image.shape[:2])\n","    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n","    return dataset_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TnuvSDLfyexN"},"outputs":[],"source":["#@markdown COCOEvaluator\n","import contextlib\n","import copy\n","import io\n","import itertools\n","import json\n","import logging\n","import numpy as np\n","import os\n","import pickle\n","from collections import OrderedDict\n","import pycocotools.mask as mask_util\n","import torch\n","from pycocotools.coco import COCO\n","from pycocotools.cocoeval import COCOeval\n","from tabulate import tabulate\n","\n","import detectron2.utils.comm as comm\n","from detectron2.config import CfgNode\n","from detectron2.data import MetadataCatalog\n","from detectron2.data.datasets.coco import convert_to_coco_json\n","from detectron2.structures import Boxes, BoxMode, pairwise_iou\n","from detectron2.utils.file_io import PathManager\n","from detectron2.utils.logger import create_small_table\n","\n","from detectron2.evaluation import DatasetEvaluator\n","\n","try:\n","    from detectron2.evaluation.fast_eval_api import COCOeval_opt\n","except ImportError:\n","    COCOeval_opt = COCOeval\n","\n","\n","class COCOEvaluator(DatasetEvaluator):\n","    \"\"\"\n","    Evaluate AR for object proposals, AP for instance detection/segmentation, AP\n","    for keypoint detection outputs using COCO's metrics.\n","    See http://cocodataset.org/#detection-eval and\n","    http://cocodataset.org/#keypoints-eval to understand its metrics.\n","    The metrics range from 0 to 100 (instead of 0 to 1), where a -1 or NaN means\n","    the metric cannot be computed (e.g. due to no predictions made).\n","\n","    In addition to COCO, this evaluator is able to support any bounding box detection,\n","    instance segmentation, or keypoint detection dataset.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        dataset_name,\n","        tasks=None,\n","        distributed=True,\n","        output_dir=None,\n","        *,\n","        max_dets_per_image=None,\n","        use_fast_impl=True,\n","        kpt_oks_sigmas=(),\n","        allow_cached_coco=True,\n","    ):\n","        \"\"\"\n","        Args:\n","            dataset_name (str): name of the dataset to be evaluated.\n","                It must have either the following corresponding metadata:\n","\n","                    \"json_file\": the path to the COCO format annotation\n","\n","                Or it must be in detectron2's standard dataset format\n","                so it can be converted to COCO format automatically.\n","            tasks (tuple[str]): tasks that can be evaluated under the given\n","                configuration. A task is one of \"bbox\", \"segm\", \"keypoints\".\n","                By default, will infer this automatically from predictions.\n","            distributed (True): if True, will collect results from all ranks and run evaluation\n","                in the main process.\n","                Otherwise, will only evaluate the results in the current process.\n","            output_dir (str): optional, an output directory to dump all\n","                results predicted on the dataset. The dump contains two files:\n","\n","                1. \"instances_predictions.pth\" a file that can be loaded with `torch.load` and\n","                   contains all the results in the format they are produced by the model.\n","                2. \"coco_instances_results.json\" a json file in COCO's result format.\n","            max_dets_per_image (int): limit on the maximum number of detections per image.\n","                By default in COCO, this limit is to 100, but this can be customized\n","                to be greater, as is needed in evaluation metrics AP fixed and AP pool\n","                (see https://arxiv.org/pdf/2102.01066.pdf)\n","                This doesn't affect keypoint evaluation.\n","            use_fast_impl (bool): use a fast but **unofficial** implementation to compute AP.\n","                Although the results should be very close to the official implementation in COCO\n","                API, it is still recommended to compute results with the official API for use in\n","                papers. The faster implementation also uses more RAM.\n","            kpt_oks_sigmas (list[float]): The sigmas used to calculate keypoint OKS.\n","                See http://cocodataset.org/#keypoints-eval\n","                When empty, it will use the defaults in COCO.\n","                Otherwise it should be the same length as ROI_KEYPOINT_HEAD.NUM_KEYPOINTS.\n","            allow_cached_coco (bool): Whether to use cached coco json from previous validation\n","                runs. You should set this to False if you need to use different validation data.\n","                Defaults to True.\n","        \"\"\"\n","        self._logger = logging.getLogger(__name__)\n","        self._distributed = distributed\n","        self._output_dir = output_dir\n","\n","        if use_fast_impl and (COCOeval_opt is COCOeval):\n","            self._logger.info(\"Fast COCO eval is not built. Falling back to official COCO eval.\")\n","            use_fast_impl = False\n","        self._use_fast_impl = use_fast_impl\n","\n","        # COCOeval requires the limit on the number of detections per image (maxDets) to be a list\n","        # with at least 3 elements. The default maxDets in COCOeval is [1, 10, 100], in which the\n","        # 3rd element (100) is used as the limit on the number of detections per image when\n","        # evaluating AP. COCOEvaluator expects an integer for max_dets_per_image, so for COCOeval,\n","        # we reformat max_dets_per_image into [1, 10, max_dets_per_image], based on the defaults.\n","        if max_dets_per_image is None:\n","            max_dets_per_image = [1, 10, 100]\n","        else:\n","            max_dets_per_image = [1, 10, max_dets_per_image]\n","        self._max_dets_per_image = max_dets_per_image\n","\n","        if tasks is not None and isinstance(tasks, CfgNode):\n","            kpt_oks_sigmas = (\n","                tasks.TEST.KEYPOINT_OKS_SIGMAS if not kpt_oks_sigmas else kpt_oks_sigmas\n","            )\n","            self._logger.warn(\n","                \"COCO Evaluator instantiated using config, this is deprecated behavior.\"\n","                \" Please pass in explicit arguments instead.\"\n","            )\n","            self._tasks = None  # Infering it from predictions should be better\n","        else:\n","            self._tasks = tasks\n","\n","        self._cpu_device = torch.device(\"cpu\")\n","\n","        self._metadata = MetadataCatalog.get(dataset_name)\n","        if not hasattr(self._metadata, \"json_file\"):\n","            if output_dir is None:\n","                raise ValueError(\n","                    \"output_dir must be provided to COCOEvaluator \"\n","                    \"for datasets not in COCO format.\"\n","                )\n","            self._logger.info(f\"Trying to convert '{dataset_name}' to COCO format ...\")\n","\n","            cache_path = os.path.join(output_dir, f\"{dataset_name}_coco_format.json\")\n","            self._metadata.json_file = cache_path\n","            convert_to_coco_json(dataset_name, cache_path, allow_cached=allow_cached_coco)\n","\n","        json_file = PathManager.get_local_path(self._metadata.json_file)\n","        with contextlib.redirect_stdout(io.StringIO()):\n","            self._coco_api = COCO(json_file)\n","\n","        # Test set json files do not contain annotations (evaluation must be\n","        # performed using the COCO evaluation server).\n","        self._do_evaluation = \"annotations\" in self._coco_api.dataset\n","        if self._do_evaluation:\n","            self._kpt_oks_sigmas = kpt_oks_sigmas\n","\n","\n","    def reset(self):\n","        self._predictions = []\n","\n","\n","    def process(self, inputs, outputs):\n","        \"\"\"\n","        Args:\n","            inputs: the inputs to a COCO model (e.g., GeneralizedRCNN).\n","                It is a list of dict. Each dict corresponds to an image and\n","                contains keys like \"height\", \"width\", \"file_name\", \"image_id\".\n","            outputs: the outputs of a COCO model. It is a list of dicts with key\n","                \"instances\" that contains :class:`Instances`.\n","        \"\"\"\n","        for input, output in zip(inputs, outputs):\n","            prediction = {\"image_id\": input[\"image_id\"]}\n","\n","            if \"instances\" in output:\n","                instances = output[\"instances\"].to(self._cpu_device)\n","                prediction[\"instances\"] = instances_to_coco_json(instances, input[\"image_id\"])\n","            if \"proposals\" in output:\n","                prediction[\"proposals\"] = output[\"proposals\"].to(self._cpu_device)\n","            if len(prediction) > 1:\n","                self._predictions.append(prediction)\n","\n","\n","    def evaluate(self, img_ids=None):\n","        \"\"\"\n","        Args:\n","            img_ids: a list of image IDs to evaluate on. Default to None for the whole dataset\n","        \"\"\"\n","        if self._distributed:\n","            comm.synchronize()\n","            predictions = comm.gather(self._predictions, dst=0)\n","            predictions = list(itertools.chain(*predictions))\n","\n","            if not comm.is_main_process():\n","                return {}\n","        else:\n","            predictions = self._predictions\n","\n","        if len(predictions) == 0:\n","            self._logger.warning(\"[COCOEvaluator] Did not receive valid predictions.\")\n","            return {}\n","\n","        if self._output_dir:\n","            PathManager.mkdirs(self._output_dir)\n","            file_path = os.path.join(self._output_dir, \"instances_predictions.pth\")\n","            with PathManager.open(file_path, \"wb\") as f:\n","                torch.save(predictions, f)\n","\n","        self._results = OrderedDict()\n","        if \"proposals\" in predictions[0]:\n","            self._eval_box_proposals(predictions)\n","        if \"instances\" in predictions[0]:\n","            self._eval_predictions(predictions, img_ids=img_ids)\n","        # Copy so the caller can do whatever with results\n","        return copy.deepcopy(self._results)\n","\n","\n","    def _tasks_from_predictions(self, predictions):\n","        \"\"\"\n","        Get COCO API \"tasks\" (i.e. iou_type) from COCO-format predictions.\n","        \"\"\"\n","        tasks = {\"bbox\"}\n","        for pred in predictions:\n","            if \"segmentation\" in pred:\n","                tasks.add(\"segm\")\n","            if \"keypoints\" in pred:\n","                tasks.add(\"keypoints\")\n","        return sorted(tasks)\n","\n","    def _eval_predictions(self, predictions, img_ids=None):\n","        \"\"\"\n","        Evaluate predictions. Fill self._results with the metrics of the tasks.\n","        \"\"\"\n","        self._logger.info(\"Preparing results for COCO format ...\")\n","        coco_results = list(itertools.chain(*[x[\"instances\"] for x in predictions]))\n","        tasks = self._tasks or self._tasks_from_predictions(coco_results)\n","\n","        # unmap the category ids for COCO\n","        if hasattr(self._metadata, \"thing_dataset_id_to_contiguous_id\"):\n","            dataset_id_to_contiguous_id = self._metadata.thing_dataset_id_to_contiguous_id\n","            all_contiguous_ids = list(dataset_id_to_contiguous_id.values())\n","            num_classes = len(all_contiguous_ids)\n","            assert min(all_contiguous_ids) == 0 and max(all_contiguous_ids) == num_classes - 1\n","\n","            reverse_id_mapping = {v: k for k, v in dataset_id_to_contiguous_id.items()}\n","            for result in coco_results:\n","                category_id = result[\"category_id\"]\n","                assert category_id < num_classes, (\n","                    f\"A prediction has class={category_id}, \"\n","                    f\"but the dataset only has {num_classes} classes and \"\n","                    f\"predicted class id should be in [0, {num_classes - 1}].\"\n","                )\n","                result[\"category_id\"] = reverse_id_mapping[category_id]\n","\n","        if self._output_dir:\n","            file_path = os.path.join(self._output_dir, \"coco_instances_results.json\")\n","            self._logger.info(\"Saving results to {}\".format(file_path))\n","            with PathManager.open(file_path, \"w\") as f:\n","                f.write(json.dumps(coco_results))\n","                f.flush()\n","\n","        if not self._do_evaluation:\n","            self._logger.info(\"Annotations are not available for evaluation.\")\n","            return\n","\n","        self._logger.info(\n","            \"Evaluating predictions with {} COCO API...\".format(\n","                \"unofficial\" if self._use_fast_impl else \"official\"\n","            )\n","        )\n","        for task in sorted(tasks):\n","            assert task in {\"bbox\", \"segm\", \"keypoints\"}, f\"Got unknown task: {task}!\"\n","            coco_eval = (\n","                _evaluate_predictions_on_coco(\n","                    self._coco_api,\n","                    coco_results,\n","                    task,\n","                    kpt_oks_sigmas=self._kpt_oks_sigmas,\n","                    use_fast_impl=self._use_fast_impl,\n","                    img_ids=img_ids,\n","                    max_dets_per_image=self._max_dets_per_image,\n","                )\n","                if len(coco_results) > 0\n","                else None  # cocoapi does not handle empty results very well\n","            )\n","\n","            res = self._derive_coco_results(\n","                coco_eval, task, class_names=self._metadata.get(\"thing_classes\")\n","            )\n","            self._results[task] = res\n","\n","    def _eval_box_proposals(self, predictions):\n","        \"\"\"\n","        Evaluate the box proposals in predictions.\n","        Fill self._results with the metrics for \"box_proposals\" task.\n","        \"\"\"\n","        if self._output_dir:\n","            # Saving generated box proposals to file.\n","            # Predicted box_proposals are in XYXY_ABS mode.\n","            bbox_mode = BoxMode.XYXY_ABS.value\n","            ids, boxes, objectness_logits = [], [], []\n","            for prediction in predictions:\n","                ids.append(prediction[\"image_id\"])\n","                boxes.append(prediction[\"proposals\"].proposal_boxes.tensor.numpy())\n","                objectness_logits.append(prediction[\"proposals\"].objectness_logits.numpy())\n","\n","            proposal_data = {\n","                \"boxes\": boxes,\n","                \"objectness_logits\": objectness_logits,\n","                \"ids\": ids,\n","                \"bbox_mode\": bbox_mode,\n","            }\n","            with PathManager.open(os.path.join(self._output_dir, \"box_proposals.pkl\"), \"wb\") as f:\n","                pickle.dump(proposal_data, f)\n","\n","        if not self._do_evaluation:\n","            self._logger.info(\"Annotations are not available for evaluation.\")\n","            return\n","\n","        self._logger.info(\"Evaluating bbox proposals ...\")\n","        res = {}\n","        areas = {\"all\": \"\", \"small\": \"s\", \"medium\": \"m\", \"large\": \"l\"}\n","        for limit in [100, 1000]:\n","            for area, suffix in areas.items():\n","                stats = _evaluate_box_proposals(predictions, self._coco_api, area=area, limit=limit)\n","                key = \"AR{}@{:d}\".format(suffix, limit)\n","                res[key] = float(stats[\"ar\"].item() * 100)\n","        self._logger.info(\"Proposal metrics: \\n\" + create_small_table(res))\n","        self._results[\"box_proposals\"] = res\n","\n","    def _derive_coco_results(self, coco_eval, iou_type, class_names=None):\n","        \"\"\"\n","        Derive the desired score numbers from summarized COCOeval.\n","\n","        Args:\n","            coco_eval (None or COCOEval): None represents no predictions from model.\n","            iou_type (str):\n","            class_names (None or list[str]): if provided, will use it to predict\n","                per-category AP.\n","\n","        Returns:\n","            a dict of {metric name: score}\n","        \"\"\"\n","\n","        metrics = {\n","            \"bbox\": [\"AP\", \"AP50\", \"AP75\", \"APs\", \"APm\", \"APl\"],\n","            \"segm\": [\"AP\", \"AP50\", \"AP75\", \"APs\", \"APm\", \"APl\"],\n","            \"keypoints\": [\"AP\", \"AP50\", \"AP75\", \"APm\", \"APl\"],\n","        }[iou_type]\n","\n","        if coco_eval is None:\n","            self._logger.warn(\"No predictions from the model!\")\n","            return {metric: float(\"nan\") for metric in metrics}\n","\n","        # the standard metrics\n","        results = {\n","            metric: float(coco_eval.stats[idx] * 100 if coco_eval.stats[idx] >= 0 else \"nan\")\n","            for idx, metric in enumerate(metrics)\n","        }\n","        self._logger.info(\n","            \"Evaluation results for {}: \\n\".format(iou_type) + create_small_table(results)\n","        )\n","        if not np.isfinite(sum(results.values())):\n","            self._logger.info(\"Some metrics cannot be computed and is shown as NaN.\")\n","\n","        if class_names is None or len(class_names) <= 1:\n","            return results\n","        # Compute per-category AP\n","        # from https://github.com/facebookresearch/Detectron/blob/a6a835f5b8208c45d0dce217ce9bbda915f44df7/detectron/datasets/json_dataset_evaluator.py#L222-L252 # noqa\n","        precisions = coco_eval.eval[\"precision\"]\n","        # precision has dims (iou, recall, cls, area range, max dets)\n","        assert len(class_names) == precisions.shape[2]\n","\n","        results_per_category = []\n","        for idx, name in enumerate(class_names):\n","            # area range index 0: all area ranges\n","            # max dets index -1: typically 100 per image\n","            precision = precisions[:, :, idx, 0, -1]\n","            precision = precision[precision > -1]\n","            ap = np.mean(precision) if precision.size else float(\"nan\")\n","            results_per_category.append((\"{}\".format(name), float(ap * 100)))\n","\n","        # tabulate it\n","        N_COLS = min(6, len(results_per_category) * 2)\n","        results_flatten = list(itertools.chain(*results_per_category))\n","        results_2d = itertools.zip_longest(*[results_flatten[i::N_COLS] for i in range(N_COLS)])\n","        table = tabulate(\n","            results_2d,\n","            tablefmt=\"pipe\",\n","            floatfmt=\".3f\",\n","            headers=[\"category\", \"AP\"] * (N_COLS // 2),\n","            numalign=\"left\",\n","        )\n","        self._logger.info(\"Per-category {} AP: \\n\".format(iou_type) + table)\n","\n","        results.update({\"AP-\" + name: ap for name, ap in results_per_category})\n","        return results\n","\n","\n","\n","def instances_to_coco_json(instances, img_id):\n","    \"\"\"\n","    Dump an \"Instances\" object to a COCO-format json that's used for evaluation.\n","\n","    Args:\n","        instances (Instances):\n","        img_id (int): the image id\n","\n","    Returns:\n","        list[dict]: list of json annotations in COCO format.\n","    \"\"\"\n","    num_instance = len(instances)\n","    if num_instance == 0:\n","        return []\n","\n","    boxes = instances.pred_boxes.tensor.numpy()\n","    boxes = BoxMode.convert(boxes, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n","    boxes = boxes.tolist()\n","    scores = instances.scores.tolist()\n","    classes = instances.pred_classes.tolist()\n","\n","    has_mask = instances.has(\"pred_masks\")\n","    if has_mask:\n","        # use RLE to encode the masks, because they are too large and takes memory\n","        # since this evaluator stores outputs of the entire dataset\n","        rles = [\n","            mask_util.encode(np.array(mask[:, :, None], order=\"F\", dtype=\"uint8\"))[0]\n","            for mask in instances.pred_masks\n","        ]\n","        for rle in rles:\n","            # \"counts\" is an array encoded by mask_util as a byte-stream. Python3's\n","            # json writer which always produces strings cannot serialize a bytestream\n","            # unless you decode it. Thankfully, utf-8 works out (which is also what\n","            # the pycocotools/_mask.pyx does).\n","            rle[\"counts\"] = rle[\"counts\"].decode(\"utf-8\")\n","\n","    has_keypoints = instances.has(\"pred_keypoints\")\n","    if has_keypoints:\n","        keypoints = instances.pred_keypoints\n","\n","    results = []\n","    for k in range(num_instance):\n","        result = {\n","            \"image_id\": img_id,\n","            \"category_id\": classes[k],\n","            \"bbox\": boxes[k],\n","            \"score\": scores[k],\n","        }\n","        if has_mask:\n","            result[\"segmentation\"] = rles[k]\n","        if has_keypoints:\n","            # In COCO annotations,\n","            # keypoints coordinates are pixel indices.\n","            # However our predictions are floating point coordinates.\n","            # Therefore we subtract 0.5 to be consistent with the annotation format.\n","            # This is the inverse of data loading logic in `datasets/coco.py`.\n","            keypoints[k][:, :2] -= 0.5\n","            result[\"keypoints\"] = keypoints[k].flatten().tolist()\n","        results.append(result)\n","    return results\n","\n","\n","# inspired from Detectron:\n","# https://github.com/facebookresearch/Detectron/blob/a6a835f5b8208c45d0dce217ce9bbda915f44df7/detectron/datasets/json_dataset_evaluator.py#L255 # noqa\n","def _evaluate_box_proposals(dataset_predictions, coco_api, thresholds=None, area=\"all\", limit=None):\n","    \"\"\"\n","    Evaluate detection proposal recall metrics. This function is a much\n","    faster alternative to the official COCO API recall evaluation code. However,\n","    it produces slightly different results.\n","    \"\"\"\n","    # Record max overlap value for each gt box\n","    # Return vector of overlap values\n","    areas = {\n","        \"all\": 0,\n","        \"small\": 1,\n","        \"medium\": 2,\n","        \"large\": 3,\n","        \"96-128\": 4,\n","        \"128-256\": 5,\n","        \"256-512\": 6,\n","        \"512-inf\": 7,\n","    }\n","    area_ranges = [\n","        [0 ** 2, 1e5 ** 2],  # all\n","        [0 ** 2, 32 ** 2],  # small\n","        [32 ** 2, 96 ** 2],  # medium\n","        [96 ** 2, 1e5 ** 2],  # large\n","        [96 ** 2, 128 ** 2],  # 96-128\n","        [128 ** 2, 256 ** 2],  # 128-256\n","        [256 ** 2, 512 ** 2],  # 256-512\n","        [512 ** 2, 1e5 ** 2],\n","    ]  # 512-inf\n","    assert area in areas, \"Unknown area range: {}\".format(area)\n","    area_range = area_ranges[areas[area]]\n","    gt_overlaps = []\n","    num_pos = 0\n","\n","    for prediction_dict in dataset_predictions:\n","        predictions = prediction_dict[\"proposals\"]\n","\n","        # sort predictions in descending order\n","        # TODO maybe remove this and make it explicit in the documentation\n","        inds = predictions.objectness_logits.sort(descending=True)[1]\n","        predictions = predictions[inds]\n","\n","        ann_ids = coco_api.getAnnIds(imgIds=prediction_dict[\"image_id\"])\n","        anno = coco_api.loadAnns(ann_ids)\n","        gt_boxes = [\n","            BoxMode.convert(obj[\"bbox\"], BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n","            for obj in anno\n","            if obj[\"iscrowd\"] == 0\n","        ]\n","        gt_boxes = torch.as_tensor(gt_boxes).reshape(-1, 4)  # guard against no boxes\n","        gt_boxes = Boxes(gt_boxes)\n","        gt_areas = torch.as_tensor([obj[\"area\"] for obj in anno if obj[\"iscrowd\"] == 0])\n","\n","        if len(gt_boxes) == 0 or len(predictions) == 0:\n","            continue\n","\n","        valid_gt_inds = (gt_areas >= area_range[0]) & (gt_areas <= area_range[1])\n","        gt_boxes = gt_boxes[valid_gt_inds]\n","\n","        num_pos += len(gt_boxes)\n","\n","        if len(gt_boxes) == 0:\n","            continue\n","\n","        if limit is not None and len(predictions) > limit:\n","            predictions = predictions[:limit]\n","\n","        overlaps = pairwise_iou(predictions.proposal_boxes, gt_boxes)\n","\n","        _gt_overlaps = torch.zeros(len(gt_boxes))\n","        for j in range(min(len(predictions), len(gt_boxes))):\n","            # find which proposal box maximally covers each gt box\n","            # and get the iou amount of coverage for each gt box\n","            max_overlaps, argmax_overlaps = overlaps.max(dim=0)\n","\n","            # find which gt box is 'best' covered (i.e. 'best' = most iou)\n","            gt_ovr, gt_ind = max_overlaps.max(dim=0)\n","            assert gt_ovr >= 0\n","            # find the proposal box that covers the best covered gt box\n","            box_ind = argmax_overlaps[gt_ind]\n","            # record the iou coverage of this gt box\n","            _gt_overlaps[j] = overlaps[box_ind, gt_ind]\n","            assert _gt_overlaps[j] == gt_ovr\n","            # mark the proposal box and the gt box as used\n","            overlaps[box_ind, :] = -1\n","            overlaps[:, gt_ind] = -1\n","\n","        # append recorded iou coverage level\n","        gt_overlaps.append(_gt_overlaps)\n","    gt_overlaps = (\n","        torch.cat(gt_overlaps, dim=0) if len(gt_overlaps) else torch.zeros(0, dtype=torch.float32)\n","    )\n","    gt_overlaps, _ = torch.sort(gt_overlaps)\n","\n","    if thresholds is None:\n","        step = 0.05\n","        thresholds = torch.arange(0.5, 0.95 + 1e-5, step, dtype=torch.float32)\n","    recalls = torch.zeros_like(thresholds)\n","    # compute recall for each iou threshold\n","    for i, t in enumerate(thresholds):\n","        recalls[i] = (gt_overlaps >= t).float().sum() / float(num_pos)\n","    # ar = 2 * np.trapz(recalls, thresholds)\n","    ar = recalls.mean()\n","    return {\n","        \"ar\": ar,\n","        \"recalls\": recalls,\n","        \"thresholds\": thresholds,\n","        \"gt_overlaps\": gt_overlaps,\n","        \"num_pos\": num_pos,\n","    }\n","\n","\n","def _evaluate_predictions_on_coco(\n","    coco_gt,\n","    coco_results,\n","    iou_type,\n","    kpt_oks_sigmas=None,\n","    use_fast_impl=True,\n","    img_ids=None,\n","    max_dets_per_image=None,\n","):\n","    \"\"\"\n","    Evaluate the coco results using COCOEval API.\n","    \"\"\"\n","    assert len(coco_results) > 0\n","\n","    if iou_type == \"segm\":\n","        coco_results = copy.deepcopy(coco_results)\n","        # When evaluating mask AP, if the results contain bbox, cocoapi will\n","        # use the box area as the area of the instance, instead of the mask area.\n","        # This leads to a different definition of small/medium/large.\n","        # We remove the bbox field to let mask AP use mask area.\n","        for c in coco_results:\n","            c.pop(\"bbox\", None)\n","\n","    coco_dt = coco_gt.loadRes(coco_results)\n","    coco_eval = (COCOeval_opt if use_fast_impl else COCOeval)(coco_gt, coco_dt, iou_type)\n","    # For COCO, the default max_dets_per_image is [1, 10, 100].\n","    if max_dets_per_image is None:\n","        max_dets_per_image = [1, 10, 100]  # Default from COCOEval\n","    else:\n","        assert (\n","            len(max_dets_per_image) >= 3\n","        ), \"COCOeval requires maxDets (and max_dets_per_image) to have length at least 3\"\n","        # In the case that user supplies a custom input for max_dets_per_image,\n","        # apply COCOevalMaxDets to evaluate AP with the custom input.\n","        if max_dets_per_image[2] != 100:\n","            coco_eval = COCOevalMaxDets(coco_gt, coco_dt, iou_type)\n","    if iou_type != \"keypoints\":\n","        coco_eval.params.maxDets = max_dets_per_image\n","\n","    if img_ids is not None:\n","        coco_eval.params.imgIds = img_ids\n","\n","    if iou_type == \"keypoints\":\n","        # Use the COCO default keypoint OKS sigmas unless overrides are specified\n","        if kpt_oks_sigmas:\n","            assert hasattr(coco_eval.params, \"kpt_oks_sigmas\"), \"pycocotools is too old!\"\n","            coco_eval.params.kpt_oks_sigmas = np.array(kpt_oks_sigmas)\n","        # COCOAPI requires every detection and every gt to have keypoints, so\n","        # we just take the first entry from both\n","        num_keypoints_dt = len(coco_results[0][\"keypoints\"]) // 3\n","        num_keypoints_gt = len(next(iter(coco_gt.anns.values()))[\"keypoints\"]) // 3\n","        num_keypoints_oks = len(coco_eval.params.kpt_oks_sigmas)\n","        assert num_keypoints_oks == num_keypoints_dt == num_keypoints_gt, (\n","            f\"[COCOEvaluator] Prediction contain {num_keypoints_dt} keypoints. \"\n","            f\"Ground truth contains {num_keypoints_gt} keypoints. \"\n","            f\"The length of cfg.TEST.KEYPOINT_OKS_SIGMAS is {num_keypoints_oks}. \"\n","            \"They have to agree with each other. For meaning of OKS, please refer to \"\n","            \"http://cocodataset.org/#keypoints-eval.\"\n","        )\n","\n","    coco_eval.evaluate()\n","    coco_eval.accumulate()\n","    coco_eval.summarize()\n","\n","    return coco_eval\n","\n","\n","class COCOevalMaxDets(COCOeval):\n","    \"\"\"\n","    Modified version of COCOeval for evaluating AP with a custom\n","    maxDets (by default for COCO, maxDets is 100)\n","    \"\"\"\n","\n","    def summarize(self):\n","        \"\"\"\n","        Compute and display summary metrics for evaluation results given\n","        a custom value for  max_dets_per_image\n","        \"\"\"\n","\n","        def _summarize(ap=1, iouThr=None, areaRng=\"all\", maxDets=100):\n","            p = self.params\n","            iStr = \" {:<18} {} @[ IoU={:<9} | area={:>6s} | maxDets={:>3d} ] = {:0.3f}\"\n","            titleStr = \"Average Precision\" if ap == 1 else \"Average Recall\"\n","            typeStr = \"(AP)\" if ap == 1 else \"(AR)\"\n","            iouStr = (\n","                \"{:0.2f}:{:0.2f}\".format(p.iouThrs[0], p.iouThrs[-1])\n","                if iouThr is None\n","                else \"{:0.2f}\".format(iouThr)\n","            )\n","\n","            aind = [i for i, aRng in enumerate(p.areaRngLbl) if aRng == areaRng]\n","            mind = [i for i, mDet in enumerate(p.maxDets) if mDet == maxDets]\n","            if ap == 1:\n","                # dimension of precision: [TxRxKxAxM]\n","                s = self.eval[\"precision\"]\n","                # IoU\n","                if iouThr is not None:\n","                    t = np.where(iouThr == p.iouThrs)[0]\n","                    s = s[t]\n","                s = s[:, :, :, aind, mind]\n","            else:\n","                # dimension of recall: [TxKxAxM]\n","                s = self.eval[\"recall\"]\n","                if iouThr is not None:\n","                    t = np.where(iouThr == p.iouThrs)[0]\n","                    s = s[t]\n","                s = s[:, :, aind, mind]\n","            if len(s[s > -1]) == 0:\n","                mean_s = -1\n","            else:\n","                mean_s = np.mean(s[s > -1])\n","            print(iStr.format(titleStr, typeStr, iouStr, areaRng, maxDets, mean_s))\n","            return mean_s\n","\n","        def _summarizeDets():\n","            stats = np.zeros((12,))\n","            # Evaluate AP using the custom limit on maximum detections per image\n","            stats[0] = _summarize(1, maxDets=self.params.maxDets[2])\n","            stats[1] = _summarize(1, iouThr=0.5, maxDets=self.params.maxDets[2])\n","            stats[2] = _summarize(1, iouThr=0.75, maxDets=self.params.maxDets[2])\n","            stats[3] = _summarize(1, areaRng=\"small\", maxDets=self.params.maxDets[2])\n","            stats[4] = _summarize(1, areaRng=\"medium\", maxDets=self.params.maxDets[2])\n","            stats[5] = _summarize(1, areaRng=\"large\", maxDets=self.params.maxDets[2])\n","            stats[6] = _summarize(0, maxDets=self.params.maxDets[0])\n","            stats[7] = _summarize(0, maxDets=self.params.maxDets[1])\n","            stats[8] = _summarize(0, maxDets=self.params.maxDets[2])\n","            stats[9] = _summarize(0, areaRng=\"small\", maxDets=self.params.maxDets[2])\n","            stats[10] = _summarize(0, areaRng=\"medium\", maxDets=self.params.maxDets[2])\n","            stats[11] = _summarize(0, areaRng=\"large\", maxDets=self.params.maxDets[2])\n","            return stats\n","\n","        def _summarizeKps():\n","            stats = np.zeros((10,))\n","            stats[0] = _summarize(1, maxDets=20)\n","            stats[1] = _summarize(1, maxDets=20, iouThr=0.5)\n","            stats[2] = _summarize(1, maxDets=20, iouThr=0.75)\n","            stats[3] = _summarize(1, maxDets=20, areaRng=\"medium\")\n","            stats[4] = _summarize(1, maxDets=20, areaRng=\"large\")\n","            stats[5] = _summarize(0, maxDets=20)\n","            stats[6] = _summarize(0, maxDets=20, iouThr=0.5)\n","            stats[7] = _summarize(0, maxDets=20, iouThr=0.75)\n","            stats[8] = _summarize(0, maxDets=20, areaRng=\"medium\")\n","            stats[9] = _summarize(0, maxDets=20, areaRng=\"large\")\n","            return stats\n","\n","        if not self.eval:\n","            raise Exception(\"Please run accumulate() first\")\n","        iouType = self.params.iouType\n","        if iouType == \"segm\" or iouType == \"bbox\":\n","            summarize = _summarizeDets\n","        elif iouType == \"keypoints\":\n","            summarize = _summarizeKps\n","        self.stats = summarize()\n","\n","    def __str__(self):\n","        self.summarize()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"rjNcp4ErHMgO"},"outputs":[],"source":["#@markdown Trainer\n","\n","class Trainer(DefaultTrainer):\n","    @classmethod\n","    def build_test_loader(cls, cfg, dataset_name):\n","        return build_detection_test_loader(cfg, dataset_name, mapper=test_mapper)\n","\n","    @classmethod\n","    def build_train_loader(cls, cfg):\n","        return build_detection_train_loader(cfg, mapper=train_mapper)\n","    \n","    @classmethod\n","    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n","        if output_folder is None:\n","            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n","        return COCOEvaluator(dataset_name, ['bbox', 'segm'], True, output_folder,\n","                             max_dets_per_image=cfg.TEST.DETECTIONS_PER_IMAGE)\n","                     \n","    def build_hooks(self):\n","        hooks = super().build_hooks()\n","        hooks.insert(-1, LossEvalHook(\n","            cfg.TEST.EVAL_PERIOD,\n","            self.model,\n","            build_detection_test_loader(\n","                self.cfg,\n","                self.cfg.DATASETS.TEST[0],\n","                mapper=test_mapper\n","            )\n","        ))\n","        return hooks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5YkgkbD-fz6p"},"outputs":[],"source":["def show_image(file: int=0, transform_list=test_transform_list):\n","    example = dataset_dicts_val[file]\n","    im = cv2.imread(example[\"file_name\"])\n","    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(16, 16), dpi=200)\n","    image, transforms = T.apply_transform_gens(transform_list, im)\n","    axs[0].imshow(im[:, :, ::-1])\n","    axs[1].imshow(image[:, :, ::-1])\n","    axs[0].set_title('Original')\n","    axs[1].set_title('Reformatted')\n","    plt.show()\n","    del im\n","    del image"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":775,"output_embedded_package_id":"1leYgH0IRDWAyU2E330Q1cUwm9BPDI6wv"},"executionInfo":{"elapsed":8365,"status":"ok","timestamp":1646355709600,"user":{"displayName":"Максим Кирилюк","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhiZlomAsRWc2ZvwiL0cRS2Nsnyf8tkYmWd5rrd_w=s64","userId":"05409930939227430098"},"user_tz":-180},"id":"DzQXtR_-l64f","outputId":"ab7097d9-b80b-49cb-d070-1492128c5202"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["show_image(0, train_transform_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJzQOfj9YKjr","outputId":"dda97cd9-e2c9-40d4-ab08-dbd324b44061"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[32m[03/04 01:01:50 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (6): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (7): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (8): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (9): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (10): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (11): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (12): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (13): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (14): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (15): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (16): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (17): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (18): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (19): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (20): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (21): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (22): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (objectness_logits): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten()\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","\u001b[32m[03/04 01:01:54 d2.data.datasets.coco]: \u001b[0mLoading data/annotations_train.json takes 3.72 seconds.\n","\u001b[32m[03/04 01:01:54 d2.data.datasets.coco]: \u001b[0mLoaded 854 images in COCO format from data/annotations_train.json\n","\u001b[32m[03/04 01:01:55 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 854 images left.\n","\u001b[32m[03/04 01:01:55 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|  category  | #instances   |\n","|:----------:|:-------------|\n","|    text    | 148984       |\n","|            |              |\u001b[0m\n","\u001b[32m[03/04 01:01:55 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/04 01:01:55 d2.data.common]: \u001b[0mSerializing 854 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/04 01:01:55 d2.data.common]: \u001b[0mSerialized dataset takes 67.82 MiB\n","\u001b[32m[03/04 01:01:58 d2.data.datasets.coco]: \u001b[0mLoaded 78 images in COCO format from data/annotations_val.json\n","\u001b[32m[03/04 01:01:58 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|  category  | #instances   |\n","|:----------:|:-------------|\n","|    text    | 12716        |\n","|            |              |\u001b[0m\n","\u001b[32m[03/04 01:01:58 d2.data.common]: \u001b[0mSerializing 78 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/04 01:01:58 d2.data.common]: \u001b[0mSerialized dataset takes 5.57 MiB\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["model_final_a3ec72.pkl: 254MB [00:07, 34.5MB/s]                           \n","Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.0' to the model due to incompatible shapes: (3, 4) in the checkpoint but (24, 4) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.1' to the model due to incompatible shapes: (3, 4) in the checkpoint but (24, 4) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.2' to the model due to incompatible shapes: (3, 4) in the checkpoint but (24, 4) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.3' to the model due to incompatible shapes: (3, 4) in the checkpoint but (24, 4) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'proposal_generator.anchor_generator.cell_anchors.4' to the model due to incompatible shapes: (3, 4) in the checkpoint but (24, 4) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.weight' to the model due to incompatible shapes: (3, 256, 1, 1) in the checkpoint but (24, 256, 1, 1) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'proposal_generator.rpn_head.objectness_logits.bias' to the model due to incompatible shapes: (3,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.weight' to the model due to incompatible shapes: (12, 256, 1, 1) in the checkpoint but (96, 256, 1, 1) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'proposal_generator.rpn_head.anchor_deltas.bias' to the model due to incompatible shapes: (12,) in the checkpoint but (96,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m[03/04 01:02:06 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n","\u001b[32m[03/04 01:03:09 d2.utils.events]: \u001b[0m eta: 4:51:20  iter: 19  total_loss: 3.097  loss_cls: 0.6396  loss_box_reg: 0.6358  loss_mask: 0.6917  loss_rpn_cls: 0.6731  loss_rpn_loc: 0.491  time: 2.9647  data_time: 0.1796  lr: 9.9905e-05  max_mem: 12023M\n","\u001b[32m[03/04 01:04:08 d2.utils.events]: \u001b[0m eta: 4:51:33  iter: 39  total_loss: 2.813  loss_cls: 0.464  loss_box_reg: 0.6685  loss_mask: 0.6769  loss_rpn_cls: 0.6243  loss_rpn_loc: 0.3514  time: 2.9542  data_time: 0.0258  lr: 0.0001998  max_mem: 12023M\n","\u001b[32m[03/04 01:05:07 d2.utils.events]: \u001b[0m eta: 4:50:44  iter: 59  total_loss: 2.586  loss_cls: 0.3606  loss_box_reg: 0.6943  loss_mask: 0.64  loss_rpn_cls: 0.5904  loss_rpn_loc: 0.316  time: 2.9576  data_time: 0.0283  lr: 0.0002997  max_mem: 12119M\n","\u001b[32m[03/04 01:06:06 d2.utils.events]: \u001b[0m eta: 4:49:28  iter: 79  total_loss: 2.293  loss_cls: 0.2777  loss_box_reg: 0.6954  loss_mask: 0.5118  loss_rpn_cls: 0.5053  loss_rpn_loc: 0.3008  time: 2.9484  data_time: 0.0254  lr: 0.00039961  max_mem: 12119M\n","\u001b[32m[03/04 01:07:05 d2.utils.events]: \u001b[0m eta: 4:48:35  iter: 99  total_loss: 2.001  loss_cls: 0.2187  loss_box_reg: 0.6977  loss_mask: 0.3786  loss_rpn_cls: 0.4208  loss_rpn_loc: 0.2905  time: 2.9556  data_time: 0.0273  lr: 0.00049951  max_mem: 12507M\n","\u001b[32m[03/04 01:08:04 d2.utils.events]: \u001b[0m eta: 4:47:27  iter: 119  total_loss: 1.772  loss_cls: 0.1898  loss_box_reg: 0.6334  loss_mask: 0.3354  loss_rpn_cls: 0.3471  loss_rpn_loc: 0.2829  time: 2.9481  data_time: 0.0242  lr: 0.00059941  max_mem: 12507M\n","\u001b[32m[03/04 01:09:02 d2.utils.events]: \u001b[0m eta: 4:46:29  iter: 139  total_loss: 1.595  loss_cls: 0.1753  loss_box_reg: 0.5282  loss_mask: 0.3319  loss_rpn_cls: 0.2858  loss_rpn_loc: 0.271  time: 2.9466  data_time: 0.0269  lr: 0.00069931  max_mem: 12507M\n","\u001b[32m[03/04 01:10:02 d2.utils.events]: \u001b[0m eta: 4:45:45  iter: 159  total_loss: 1.475  loss_cls: 0.1563  loss_box_reg: 0.4967  loss_mask: 0.3099  loss_rpn_cls: 0.2358  loss_rpn_loc: 0.2873  time: 2.9488  data_time: 0.0265  lr: 0.00079921  max_mem: 12507M\n","\u001b[32m[03/04 01:11:01 d2.utils.events]: \u001b[0m eta: 4:44:47  iter: 179  total_loss: 1.369  loss_cls: 0.1439  loss_box_reg: 0.4401  loss_mask: 0.3002  loss_rpn_cls: 0.2189  loss_rpn_loc: 0.2562  time: 2.9496  data_time: 0.0242  lr: 0.00089911  max_mem: 12507M\n","\u001b[32m[03/04 01:12:01 d2.utils.events]: \u001b[0m eta: 4:44:31  iter: 199  total_loss: 1.334  loss_cls: 0.1424  loss_box_reg: 0.4424  loss_mask: 0.2829  loss_rpn_cls: 0.1983  loss_rpn_loc: 0.2467  time: 2.9551  data_time: 0.0279  lr: 0.000999  max_mem: 12507M\n","\u001b[32m[03/04 01:12:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 01:13:12 d2.utils.events]: \u001b[0m eta: 4:44:23  iter: 219  total_loss: 1.289  loss_cls: 0.1381  loss_box_reg: 0.4418  loss_mask: 0.3035  loss_rpn_cls: 0.1801  loss_rpn_loc: 0.2317  time: 3.0115  data_time: 0.0287  lr: 0.0010989  max_mem: 12507M\n","\u001b[32m[03/04 01:14:16 d2.utils.events]: \u001b[0m eta: 4:44:09  iter: 239  total_loss: 1.281  loss_cls: 0.1343  loss_box_reg: 0.436  loss_mask: 0.2932  loss_rpn_cls: 0.1752  loss_rpn_loc: 0.2372  time: 3.0244  data_time: 0.0309  lr: 0.0011988  max_mem: 12507M\n","\u001b[32m[03/04 01:15:19 d2.utils.events]: \u001b[0m eta: 4:43:46  iter: 259  total_loss: 1.22  loss_cls: 0.1267  loss_box_reg: 0.4274  loss_mask: 0.2825  loss_rpn_cls: 0.1482  loss_rpn_loc: 0.2188  time: 3.0338  data_time: 0.0304  lr: 0.0012987  max_mem: 12507M\n","\u001b[32m[03/04 01:16:23 d2.utils.events]: \u001b[0m eta: 4:43:31  iter: 279  total_loss: 1.126  loss_cls: 0.1226  loss_box_reg: 0.3944  loss_mask: 0.2831  loss_rpn_cls: 0.1332  loss_rpn_loc: 0.2008  time: 3.0474  data_time: 0.0354  lr: 0.0013986  max_mem: 12507M\n","\u001b[32m[03/04 01:17:25 d2.utils.events]: \u001b[0m eta: 4:43:30  iter: 299  total_loss: 1.167  loss_cls: 0.1118  loss_box_reg: 0.4332  loss_mask: 0.2996  loss_rpn_cls: 0.1263  loss_rpn_loc: 0.2174  time: 3.0521  data_time: 0.0317  lr: 0.0014985  max_mem: 12507M\n","\u001b[32m[03/04 01:18:29 d2.utils.events]: \u001b[0m eta: 4:43:17  iter: 319  total_loss: 1.079  loss_cls: 0.1056  loss_box_reg: 0.386  loss_mask: 0.2871  loss_rpn_cls: 0.1178  loss_rpn_loc: 0.1992  time: 3.0584  data_time: 0.0315  lr: 0.0015984  max_mem: 12507M\n","\u001b[32m[03/04 01:19:32 d2.utils.events]: \u001b[0m eta: 4:43:18  iter: 339  total_loss: 1.077  loss_cls: 0.1142  loss_box_reg: 0.3926  loss_mask: 0.2792  loss_rpn_cls: 0.1169  loss_rpn_loc: 0.197  time: 3.0646  data_time: 0.0322  lr: 0.0016983  max_mem: 12507M\n","\u001b[32m[03/04 01:20:35 d2.utils.events]: \u001b[0m eta: 4:43:21  iter: 359  total_loss: 1.057  loss_cls: 0.107  loss_box_reg: 0.3896  loss_mask: 0.2662  loss_rpn_cls: 0.106  loss_rpn_loc: 0.1958  time: 3.0686  data_time: 0.0317  lr: 0.0017982  max_mem: 12507M\n","\u001b[32m[03/04 01:21:37 d2.utils.events]: \u001b[0m eta: 4:42:38  iter: 379  total_loss: 1.11  loss_cls: 0.1142  loss_box_reg: 0.3876  loss_mask: 0.2873  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.1985  time: 3.0722  data_time: 0.0335  lr: 0.0018981  max_mem: 12507M\n","\u001b[32m[03/04 01:22:39 d2.utils.events]: \u001b[0m eta: 4:41:59  iter: 399  total_loss: 1.113  loss_cls: 0.1178  loss_box_reg: 0.393  loss_mask: 0.2895  loss_rpn_cls: 0.1163  loss_rpn_loc: 0.2011  time: 3.0734  data_time: 0.0327  lr: 0.001998  max_mem: 12507M\n","\u001b[32m[03/04 01:23:40 d2.utils.events]: \u001b[0m eta: 4:40:42  iter: 419  total_loss: 1.094  loss_cls: 0.1135  loss_box_reg: 0.3852  loss_mask: 0.2696  loss_rpn_cls: 0.1237  loss_rpn_loc: 0.2047  time: 3.0720  data_time: 0.0358  lr: 0.0020979  max_mem: 12712M\n","\u001b[32m[03/04 01:24:42 d2.utils.events]: \u001b[0m eta: 4:40:23  iter: 439  total_loss: 1.097  loss_cls: 0.1117  loss_box_reg: 0.3962  loss_mask: 0.2713  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.2009  time: 3.0735  data_time: 0.0311  lr: 0.0021978  max_mem: 12712M\n","\u001b[32m[03/04 01:25:44 d2.utils.events]: \u001b[0m eta: 4:39:47  iter: 459  total_loss: 1.076  loss_cls: 0.1053  loss_box_reg: 0.3873  loss_mask: 0.2842  loss_rpn_cls: 0.09618  loss_rpn_loc: 0.1956  time: 3.0752  data_time: 0.0342  lr: 0.0022977  max_mem: 12712M\n","\u001b[32m[03/04 01:26:47 d2.utils.events]: \u001b[0m eta: 4:39:16  iter: 479  total_loss: 1.053  loss_cls: 0.1016  loss_box_reg: 0.376  loss_mask: 0.2687  loss_rpn_cls: 0.0899  loss_rpn_loc: 0.1941  time: 3.0769  data_time: 0.0321  lr: 0.0023976  max_mem: 12712M\n","\u001b[32m[03/04 01:27:49 d2.utils.events]: \u001b[0m eta: 4:38:40  iter: 499  total_loss: 1.035  loss_cls: 0.09899  loss_box_reg: 0.3706  loss_mask: 0.2807  loss_rpn_cls: 0.08489  loss_rpn_loc: 0.1927  time: 3.0790  data_time: 0.0326  lr: 0.0024975  max_mem: 12712M\n","\u001b[32m[03/04 01:28:52 d2.utils.events]: \u001b[0m eta: 4:38:06  iter: 519  total_loss: 1.009  loss_cls: 0.09452  loss_box_reg: 0.3647  loss_mask: 0.2736  loss_rpn_cls: 0.09213  loss_rpn_loc: 0.1925  time: 3.0804  data_time: 0.0333  lr: 0.0025974  max_mem: 12712M\n","\u001b[32m[03/04 01:29:54 d2.utils.events]: \u001b[0m eta: 4:37:19  iter: 539  total_loss: 1.034  loss_cls: 0.1041  loss_box_reg: 0.3812  loss_mask: 0.281  loss_rpn_cls: 0.08322  loss_rpn_loc: 0.188  time: 3.0811  data_time: 0.0306  lr: 0.0026973  max_mem: 12712M\n","\u001b[32m[03/04 01:30:56 d2.utils.events]: \u001b[0m eta: 4:36:36  iter: 559  total_loss: 1.037  loss_cls: 0.1003  loss_box_reg: 0.3644  loss_mask: 0.2852  loss_rpn_cls: 0.08108  loss_rpn_loc: 0.1952  time: 3.0823  data_time: 0.0309  lr: 0.0027972  max_mem: 12712M\n","\u001b[32m[03/04 01:31:58 d2.utils.events]: \u001b[0m eta: 4:35:53  iter: 579  total_loss: 1.017  loss_cls: 0.1029  loss_box_reg: 0.3683  loss_mask: 0.2711  loss_rpn_cls: 0.07992  loss_rpn_loc: 0.1943  time: 3.0834  data_time: 0.0282  lr: 0.0028971  max_mem: 12712M\n","\u001b[32m[03/04 01:33:01 d2.utils.events]: \u001b[0m eta: 4:35:19  iter: 599  total_loss: 0.9732  loss_cls: 0.09581  loss_box_reg: 0.3585  loss_mask: 0.2656  loss_rpn_cls: 0.07535  loss_rpn_loc: 0.183  time: 3.0843  data_time: 0.0327  lr: 0.002997  max_mem: 12712M\n","\u001b[32m[03/04 01:34:03 d2.utils.events]: \u001b[0m eta: 4:34:41  iter: 619  total_loss: 0.9699  loss_cls: 0.09602  loss_box_reg: 0.3636  loss_mask: 0.2654  loss_rpn_cls: 0.07591  loss_rpn_loc: 0.1815  time: 3.0853  data_time: 0.0326  lr: 0.0030969  max_mem: 12712M\n","\u001b[32m[03/04 01:35:07 d2.utils.events]: \u001b[0m eta: 4:33:54  iter: 639  total_loss: 0.9823  loss_cls: 0.09816  loss_box_reg: 0.3676  loss_mask: 0.2791  loss_rpn_cls: 0.07163  loss_rpn_loc: 0.1708  time: 3.0889  data_time: 0.0347  lr: 0.0031968  max_mem: 12869M\n","\u001b[32m[03/04 01:36:10 d2.utils.events]: \u001b[0m eta: 4:33:10  iter: 659  total_loss: 0.9603  loss_cls: 0.09777  loss_box_reg: 0.3513  loss_mask: 0.2658  loss_rpn_cls: 0.06994  loss_rpn_loc: 0.1712  time: 3.0905  data_time: 0.0337  lr: 0.0032967  max_mem: 12869M\n","\u001b[32m[03/04 01:37:12 d2.utils.events]: \u001b[0m eta: 4:32:24  iter: 679  total_loss: 1.01  loss_cls: 0.09441  loss_box_reg: 0.3693  loss_mask: 0.2755  loss_rpn_cls: 0.07051  loss_rpn_loc: 0.1843  time: 3.0913  data_time: 0.0310  lr: 0.0033966  max_mem: 12869M\n","\u001b[32m[03/04 01:38:14 d2.utils.events]: \u001b[0m eta: 4:31:28  iter: 699  total_loss: 0.9611  loss_cls: 0.08703  loss_box_reg: 0.3462  loss_mask: 0.2619  loss_rpn_cls: 0.07381  loss_rpn_loc: 0.1728  time: 3.0918  data_time: 0.0339  lr: 0.0034965  max_mem: 12869M\n","\u001b[32m[03/04 01:39:18 d2.utils.events]: \u001b[0m eta: 4:30:35  iter: 719  total_loss: 0.9722  loss_cls: 0.09157  loss_box_reg: 0.3563  loss_mask: 0.2602  loss_rpn_cls: 0.06531  loss_rpn_loc: 0.1869  time: 3.0939  data_time: 0.0327  lr: 0.0035964  max_mem: 12869M\n","\u001b[32m[03/04 01:40:20 d2.utils.events]: \u001b[0m eta: 4:29:49  iter: 739  total_loss: 1.002  loss_cls: 0.08957  loss_box_reg: 0.3602  loss_mask: 0.2625  loss_rpn_cls: 0.07639  loss_rpn_loc: 0.1934  time: 3.0946  data_time: 0.0277  lr: 0.0036963  max_mem: 12869M\n","\u001b[32m[03/04 01:41:23 d2.utils.events]: \u001b[0m eta: 4:29:20  iter: 759  total_loss: 1.012  loss_cls: 0.1009  loss_box_reg: 0.3715  loss_mask: 0.2666  loss_rpn_cls: 0.07423  loss_rpn_loc: 0.1872  time: 3.0963  data_time: 0.0313  lr: 0.0037962  max_mem: 12869M\n","\u001b[32m[03/04 01:42:27 d2.utils.events]: \u001b[0m eta: 4:28:26  iter: 779  total_loss: 0.9608  loss_cls: 0.08402  loss_box_reg: 0.3617  loss_mask: 0.2685  loss_rpn_cls: 0.06448  loss_rpn_loc: 0.1693  time: 3.0986  data_time: 0.0323  lr: 0.0038961  max_mem: 12869M\n","\u001b[32m[03/04 01:43:30 d2.utils.events]: \u001b[0m eta: 4:27:36  iter: 799  total_loss: 0.9843  loss_cls: 0.09261  loss_box_reg: 0.3553  loss_mask: 0.2797  loss_rpn_cls: 0.06907  loss_rpn_loc: 0.1751  time: 3.1003  data_time: 0.0341  lr: 0.003996  max_mem: 12869M\n","\u001b[32m[03/04 01:44:33 d2.utils.events]: \u001b[0m eta: 4:26:58  iter: 819  total_loss: 0.9766  loss_cls: 0.09038  loss_box_reg: 0.3495  loss_mask: 0.2699  loss_rpn_cls: 0.06586  loss_rpn_loc: 0.1793  time: 3.1016  data_time: 0.0338  lr: 0.0040959  max_mem: 12869M\n","\u001b[32m[03/04 01:45:36 d2.utils.events]: \u001b[0m eta: 4:26:07  iter: 839  total_loss: 0.974  loss_cls: 0.09493  loss_box_reg: 0.3487  loss_mask: 0.2619  loss_rpn_cls: 0.09196  loss_rpn_loc: 0.1833  time: 3.1025  data_time: 0.0320  lr: 0.0041958  max_mem: 12869M\n","\u001b[32m[03/04 01:46:38 d2.utils.events]: \u001b[0m eta: 4:25:09  iter: 859  total_loss: 0.9382  loss_cls: 0.08632  loss_box_reg: 0.3475  loss_mask: 0.2565  loss_rpn_cls: 0.09521  loss_rpn_loc: 0.1638  time: 3.1026  data_time: 0.0313  lr: 0.0042957  max_mem: 12869M\n","\u001b[32m[03/04 01:47:41 d2.utils.events]: \u001b[0m eta: 4:24:15  iter: 879  total_loss: 0.9899  loss_cls: 0.09386  loss_box_reg: 0.3713  loss_mask: 0.2808  loss_rpn_cls: 0.06584  loss_rpn_loc: 0.1841  time: 3.1036  data_time: 0.0349  lr: 0.0043956  max_mem: 12869M\n","\u001b[32m[03/04 01:48:44 d2.utils.events]: \u001b[0m eta: 4:23:19  iter: 899  total_loss: 0.9523  loss_cls: 0.0953  loss_box_reg: 0.3632  loss_mask: 0.2641  loss_rpn_cls: 0.06446  loss_rpn_loc: 0.1807  time: 3.1046  data_time: 0.0350  lr: 0.0044955  max_mem: 12869M\n","\u001b[32m[03/04 01:49:46 d2.utils.events]: \u001b[0m eta: 4:22:15  iter: 919  total_loss: 0.9775  loss_cls: 0.07942  loss_box_reg: 0.3524  loss_mask: 0.2608  loss_rpn_cls: 0.06467  loss_rpn_loc: 0.1785  time: 3.1046  data_time: 0.0324  lr: 0.0045954  max_mem: 12869M\n","\u001b[32m[03/04 01:50:49 d2.utils.events]: \u001b[0m eta: 4:21:19  iter: 939  total_loss: 0.9833  loss_cls: 0.09322  loss_box_reg: 0.3727  loss_mask: 0.2696  loss_rpn_cls: 0.06732  loss_rpn_loc: 0.1788  time: 3.1053  data_time: 0.0297  lr: 0.0046953  max_mem: 12869M\n","\u001b[32m[03/04 01:51:52 d2.utils.events]: \u001b[0m eta: 4:20:21  iter: 959  total_loss: 0.945  loss_cls: 0.08914  loss_box_reg: 0.3368  loss_mask: 0.2527  loss_rpn_cls: 0.06546  loss_rpn_loc: 0.1756  time: 3.1062  data_time: 0.0366  lr: 0.0047952  max_mem: 12869M\n","\u001b[32m[03/04 01:52:55 d2.utils.events]: \u001b[0m eta: 4:19:27  iter: 979  total_loss: 0.955  loss_cls: 0.08461  loss_box_reg: 0.357  loss_mask: 0.2706  loss_rpn_cls: 0.06674  loss_rpn_loc: 0.1585  time: 3.1072  data_time: 0.0320  lr: 0.0048951  max_mem: 12869M\n","\u001b[32m[03/04 01:54:01 d2.utils.events]: \u001b[0m eta: 4:18:35  iter: 999  total_loss: 0.9053  loss_cls: 0.08001  loss_box_reg: 0.3305  loss_mask: 0.2582  loss_rpn_cls: 0.05769  loss_rpn_loc: 0.1635  time: 3.1088  data_time: 0.0335  lr: 0.004995  max_mem: 12869M\n","\u001b[32m[03/04 01:55:04 d2.utils.events]: \u001b[0m eta: 4:17:42  iter: 1019  total_loss: 0.9779  loss_cls: 0.08589  loss_box_reg: 0.3565  loss_mask: 0.2647  loss_rpn_cls: 0.1094  loss_rpn_loc: 0.1843  time: 3.1089  data_time: 0.0362  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 01:56:04 d2.utils.events]: \u001b[0m eta: 4:16:44  iter: 1039  total_loss: 0.8917  loss_cls: 0.07971  loss_box_reg: 0.3421  loss_mask: 0.2538  loss_rpn_cls: 0.05784  loss_rpn_loc: 0.1563  time: 3.1073  data_time: 0.0340  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 01:57:06 d2.utils.events]: \u001b[0m eta: 4:15:53  iter: 1059  total_loss: 0.9301  loss_cls: 0.07791  loss_box_reg: 0.3445  loss_mask: 0.2586  loss_rpn_cls: 0.06308  loss_rpn_loc: 0.163  time: 3.1068  data_time: 0.0336  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 01:58:09 d2.utils.events]: \u001b[0m eta: 4:15:19  iter: 1079  total_loss: 0.9313  loss_cls: 0.0904  loss_box_reg: 0.3551  loss_mask: 0.2738  loss_rpn_cls: 0.06218  loss_rpn_loc: 0.1739  time: 3.1074  data_time: 0.0310  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 01:59:11 d2.utils.events]: \u001b[0m eta: 4:14:28  iter: 1099  total_loss: 0.9253  loss_cls: 0.08263  loss_box_reg: 0.3426  loss_mask: 0.2572  loss_rpn_cls: 0.06254  loss_rpn_loc: 0.1661  time: 3.1080  data_time: 0.0345  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:00:15 d2.utils.events]: \u001b[0m eta: 4:13:42  iter: 1119  total_loss: 0.9182  loss_cls: 0.07525  loss_box_reg: 0.3395  loss_mask: 0.2654  loss_rpn_cls: 0.05973  loss_rpn_loc: 0.1674  time: 3.1090  data_time: 0.0290  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:01:18 d2.utils.events]: \u001b[0m eta: 4:12:56  iter: 1139  total_loss: 0.9135  loss_cls: 0.07568  loss_box_reg: 0.3418  loss_mask: 0.2719  loss_rpn_cls: 0.0516  loss_rpn_loc: 0.1694  time: 3.1100  data_time: 0.0333  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:02:20 d2.utils.events]: \u001b[0m eta: 4:12:02  iter: 1159  total_loss: 0.8726  loss_cls: 0.07475  loss_box_reg: 0.3247  loss_mask: 0.2446  loss_rpn_cls: 0.05367  loss_rpn_loc: 0.1644  time: 3.1099  data_time: 0.0327  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:03:23 d2.utils.events]: \u001b[0m eta: 4:11:04  iter: 1179  total_loss: 0.9126  loss_cls: 0.07816  loss_box_reg: 0.3528  loss_mask: 0.2541  loss_rpn_cls: 0.05569  loss_rpn_loc: 0.1635  time: 3.1102  data_time: 0.0289  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:04:26 d2.utils.events]: \u001b[0m eta: 4:10:14  iter: 1199  total_loss: 0.8846  loss_cls: 0.08051  loss_box_reg: 0.3363  loss_mask: 0.2783  loss_rpn_cls: 0.04934  loss_rpn_loc: 0.1481  time: 3.1109  data_time: 0.0324  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:05:28 d2.utils.events]: \u001b[0m eta: 4:09:13  iter: 1219  total_loss: 0.8594  loss_cls: 0.07219  loss_box_reg: 0.322  loss_mask: 0.2592  loss_rpn_cls: 0.04687  loss_rpn_loc: 0.1542  time: 3.1109  data_time: 0.0302  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:06:31 d2.utils.events]: \u001b[0m eta: 4:08:11  iter: 1239  total_loss: 0.8985  loss_cls: 0.08057  loss_box_reg: 0.3295  loss_mask: 0.2546  loss_rpn_cls: 0.05552  loss_rpn_loc: 0.1642  time: 3.1114  data_time: 0.0299  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:07:34 d2.utils.events]: \u001b[0m eta: 4:07:10  iter: 1259  total_loss: 0.8726  loss_cls: 0.07618  loss_box_reg: 0.343  loss_mask: 0.256  loss_rpn_cls: 0.05154  loss_rpn_loc: 0.1574  time: 3.1120  data_time: 0.0304  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:08:37 d2.utils.events]: \u001b[0m eta: 4:06:05  iter: 1279  total_loss: 0.8802  loss_cls: 0.08174  loss_box_reg: 0.3428  loss_mask: 0.2503  loss_rpn_cls: 0.04871  loss_rpn_loc: 0.156  time: 3.1128  data_time: 0.0286  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:09:40 d2.utils.events]: \u001b[0m eta: 4:05:08  iter: 1299  total_loss: 0.9072  loss_cls: 0.0801  loss_box_reg: 0.3451  loss_mask: 0.2772  loss_rpn_cls: 0.05615  loss_rpn_loc: 0.1651  time: 3.1136  data_time: 0.0340  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:10:43 d2.utils.events]: \u001b[0m eta: 4:04:07  iter: 1319  total_loss: 0.8966  loss_cls: 0.08271  loss_box_reg: 0.3354  loss_mask: 0.2702  loss_rpn_cls: 0.05048  loss_rpn_loc: 0.1553  time: 3.1142  data_time: 0.0326  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:11:47 d2.utils.events]: \u001b[0m eta: 4:02:59  iter: 1339  total_loss: 0.8718  loss_cls: 0.07521  loss_box_reg: 0.3367  loss_mask: 0.2646  loss_rpn_cls: 0.04642  loss_rpn_loc: 0.1506  time: 3.1152  data_time: 0.0290  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:12:50 d2.utils.events]: \u001b[0m eta: 4:01:57  iter: 1359  total_loss: 0.8743  loss_cls: 0.0718  loss_box_reg: 0.335  loss_mask: 0.2633  loss_rpn_cls: 0.04893  loss_rpn_loc: 0.1519  time: 3.1153  data_time: 0.0278  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:13:52 d2.utils.events]: \u001b[0m eta: 4:00:53  iter: 1379  total_loss: 0.8484  loss_cls: 0.07133  loss_box_reg: 0.3393  loss_mask: 0.2518  loss_rpn_cls: 0.04254  loss_rpn_loc: 0.146  time: 3.1156  data_time: 0.0331  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:14:55 d2.utils.events]: \u001b[0m eta: 3:59:53  iter: 1399  total_loss: 0.8493  loss_cls: 0.07521  loss_box_reg: 0.3247  loss_mask: 0.2585  loss_rpn_cls: 0.05059  loss_rpn_loc: 0.1439  time: 3.1158  data_time: 0.0315  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:15:58 d2.utils.events]: \u001b[0m eta: 3:58:56  iter: 1419  total_loss: 0.861  loss_cls: 0.06869  loss_box_reg: 0.3365  loss_mask: 0.2567  loss_rpn_cls: 0.04186  loss_rpn_loc: 0.1508  time: 3.1163  data_time: 0.0349  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:17:01 d2.utils.events]: \u001b[0m eta: 3:57:54  iter: 1439  total_loss: 0.8892  loss_cls: 0.07524  loss_box_reg: 0.3366  loss_mask: 0.2678  loss_rpn_cls: 0.05337  loss_rpn_loc: 0.1521  time: 3.1167  data_time: 0.0360  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:18:02 d2.utils.events]: \u001b[0m eta: 3:56:51  iter: 1459  total_loss: 0.8277  loss_cls: 0.06613  loss_box_reg: 0.3179  loss_mask: 0.2625  loss_rpn_cls: 0.05187  loss_rpn_loc: 0.1365  time: 3.1159  data_time: 0.0303  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:19:04 d2.utils.events]: \u001b[0m eta: 3:55:49  iter: 1479  total_loss: 0.9138  loss_cls: 0.07673  loss_box_reg: 0.3456  loss_mask: 0.2715  loss_rpn_cls: 0.04484  loss_rpn_loc: 0.1469  time: 3.1158  data_time: 0.0347  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:20:07 d2.utils.events]: \u001b[0m eta: 3:54:46  iter: 1499  total_loss: 0.8354  loss_cls: 0.07026  loss_box_reg: 0.3262  loss_mask: 0.26  loss_rpn_cls: 0.04119  loss_rpn_loc: 0.1425  time: 3.1162  data_time: 0.0288  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:21:09 d2.utils.events]: \u001b[0m eta: 3:53:43  iter: 1519  total_loss: 0.8279  loss_cls: 0.0707  loss_box_reg: 0.3213  loss_mask: 0.2537  loss_rpn_cls: 0.03984  loss_rpn_loc: 0.1465  time: 3.1159  data_time: 0.0304  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:22:12 d2.utils.events]: \u001b[0m eta: 3:52:47  iter: 1539  total_loss: 0.8581  loss_cls: 0.07472  loss_box_reg: 0.3385  loss_mask: 0.2605  loss_rpn_cls: 0.04407  loss_rpn_loc: 0.1542  time: 3.1165  data_time: 0.0351  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:23:15 d2.utils.events]: \u001b[0m eta: 3:51:48  iter: 1559  total_loss: 0.8334  loss_cls: 0.07092  loss_box_reg: 0.3271  loss_mask: 0.2534  loss_rpn_cls: 0.04377  loss_rpn_loc: 0.1398  time: 3.1167  data_time: 0.0312  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:24:17 d2.utils.events]: \u001b[0m eta: 3:50:43  iter: 1579  total_loss: 0.8737  loss_cls: 0.07442  loss_box_reg: 0.3474  loss_mask: 0.2601  loss_rpn_cls: 0.04422  loss_rpn_loc: 0.149  time: 3.1165  data_time: 0.0292  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:25:19 d2.utils.events]: \u001b[0m eta: 3:49:43  iter: 1599  total_loss: 0.8079  loss_cls: 0.06854  loss_box_reg: 0.3074  loss_mask: 0.245  loss_rpn_cls: 0.04084  loss_rpn_loc: 0.1468  time: 3.1163  data_time: 0.0308  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:26:22 d2.utils.events]: \u001b[0m eta: 3:48:40  iter: 1619  total_loss: 0.8849  loss_cls: 0.07387  loss_box_reg: 0.331  loss_mask: 0.2657  loss_rpn_cls: 0.03847  loss_rpn_loc: 0.1496  time: 3.1166  data_time: 0.0317  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:27:25 d2.utils.events]: \u001b[0m eta: 3:47:39  iter: 1639  total_loss: 0.8787  loss_cls: 0.08167  loss_box_reg: 0.345  loss_mask: 0.2677  loss_rpn_cls: 0.04188  loss_rpn_loc: 0.1453  time: 3.1172  data_time: 0.0333  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:28:29 d2.utils.events]: \u001b[0m eta: 3:46:41  iter: 1659  total_loss: 0.8641  loss_cls: 0.07727  loss_box_reg: 0.333  loss_mask: 0.2643  loss_rpn_cls: 0.04358  loss_rpn_loc: 0.1452  time: 3.1179  data_time: 0.0329  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:29:32 d2.utils.events]: \u001b[0m eta: 3:45:44  iter: 1679  total_loss: 0.8432  loss_cls: 0.06785  loss_box_reg: 0.3332  loss_mask: 0.2568  loss_rpn_cls: 0.03767  loss_rpn_loc: 0.1455  time: 3.1183  data_time: 0.0279  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:30:35 d2.utils.events]: \u001b[0m eta: 3:44:45  iter: 1699  total_loss: 0.8425  loss_cls: 0.07141  loss_box_reg: 0.3172  loss_mask: 0.2575  loss_rpn_cls: 0.04105  loss_rpn_loc: 0.1486  time: 3.1187  data_time: 0.0343  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:31:37 d2.utils.events]: \u001b[0m eta: 3:43:39  iter: 1719  total_loss: 0.8267  loss_cls: 0.07419  loss_box_reg: 0.3234  loss_mask: 0.2417  loss_rpn_cls: 0.04344  loss_rpn_loc: 0.1423  time: 3.1187  data_time: 0.0350  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:32:40 d2.utils.events]: \u001b[0m eta: 3:42:38  iter: 1739  total_loss: 0.834  loss_cls: 0.06904  loss_box_reg: 0.3155  loss_mask: 0.2612  loss_rpn_cls: 0.0414  loss_rpn_loc: 0.1547  time: 3.1190  data_time: 0.0307  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:33:43 d2.utils.events]: \u001b[0m eta: 3:41:31  iter: 1759  total_loss: 0.8724  loss_cls: 0.07335  loss_box_reg: 0.3259  loss_mask: 0.2661  loss_rpn_cls: 0.04061  loss_rpn_loc: 0.1503  time: 3.1192  data_time: 0.0353  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:34:46 d2.utils.events]: \u001b[0m eta: 3:40:29  iter: 1779  total_loss: 0.8401  loss_cls: 0.07384  loss_box_reg: 0.3303  loss_mask: 0.2554  loss_rpn_cls: 0.04271  loss_rpn_loc: 0.141  time: 3.1198  data_time: 0.0322  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:35:49 d2.utils.events]: \u001b[0m eta: 3:39:26  iter: 1799  total_loss: 0.8154  loss_cls: 0.06607  loss_box_reg: 0.3091  loss_mask: 0.2543  loss_rpn_cls: 0.03996  loss_rpn_loc: 0.1423  time: 3.1201  data_time: 0.0367  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:36:52 d2.utils.events]: \u001b[0m eta: 3:38:19  iter: 1819  total_loss: 0.8416  loss_cls: 0.06451  loss_box_reg: 0.3248  loss_mask: 0.2618  loss_rpn_cls: 0.03907  loss_rpn_loc: 0.1373  time: 3.1202  data_time: 0.0303  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:37:54 d2.utils.events]: \u001b[0m eta: 3:37:11  iter: 1839  total_loss: 0.8202  loss_cls: 0.06891  loss_box_reg: 0.3255  loss_mask: 0.2496  loss_rpn_cls: 0.034  loss_rpn_loc: 0.1387  time: 3.1201  data_time: 0.0312  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:38:57 d2.utils.events]: \u001b[0m eta: 3:36:09  iter: 1859  total_loss: 0.8818  loss_cls: 0.06844  loss_box_reg: 0.3358  loss_mask: 0.263  loss_rpn_cls: 0.03586  loss_rpn_loc: 0.1451  time: 3.1204  data_time: 0.0284  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:39:59 d2.utils.events]: \u001b[0m eta: 3:35:02  iter: 1879  total_loss: 0.8002  loss_cls: 0.06189  loss_box_reg: 0.3178  loss_mask: 0.2543  loss_rpn_cls: 0.03412  loss_rpn_loc: 0.1428  time: 3.1204  data_time: 0.0298  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:41:02 d2.utils.events]: \u001b[0m eta: 3:33:58  iter: 1899  total_loss: 0.8142  loss_cls: 0.07721  loss_box_reg: 0.3154  loss_mask: 0.2476  loss_rpn_cls: 0.04239  loss_rpn_loc: 0.143  time: 3.1207  data_time: 0.0319  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:42:05 d2.utils.events]: \u001b[0m eta: 3:33:00  iter: 1919  total_loss: 0.8535  loss_cls: 0.06811  loss_box_reg: 0.3381  loss_mask: 0.2626  loss_rpn_cls: 0.04195  loss_rpn_loc: 0.1463  time: 3.1210  data_time: 0.0378  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:43:08 d2.utils.events]: \u001b[0m eta: 3:31:57  iter: 1939  total_loss: 0.7944  loss_cls: 0.06481  loss_box_reg: 0.3183  loss_mask: 0.2492  loss_rpn_cls: 0.03378  loss_rpn_loc: 0.1347  time: 3.1211  data_time: 0.0327  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:44:10 d2.utils.events]: \u001b[0m eta: 3:30:51  iter: 1959  total_loss: 0.8158  loss_cls: 0.06525  loss_box_reg: 0.3059  loss_mask: 0.2449  loss_rpn_cls: 0.03784  loss_rpn_loc: 0.1387  time: 3.1210  data_time: 0.0335  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:45:13 d2.utils.events]: \u001b[0m eta: 3:29:47  iter: 1979  total_loss: 0.8231  loss_cls: 0.0651  loss_box_reg: 0.3045  loss_mask: 0.243  loss_rpn_cls: 0.03852  loss_rpn_loc: 0.1386  time: 3.1211  data_time: 0.0317  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:46:18 d2.utils.events]: \u001b[0m eta: 3:28:42  iter: 1999  total_loss: 0.8397  loss_cls: 0.0669  loss_box_reg: 0.3318  loss_mask: 0.2497  loss_rpn_cls: 0.03703  loss_rpn_loc: 0.1447  time: 3.1214  data_time: 0.0325  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:47:21 d2.utils.events]: \u001b[0m eta: 3:27:43  iter: 2019  total_loss: 0.8073  loss_cls: 0.06171  loss_box_reg: 0.3174  loss_mask: 0.2568  loss_rpn_cls: 0.03831  loss_rpn_loc: 0.1341  time: 3.1217  data_time: 0.0330  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:48:24 d2.utils.events]: \u001b[0m eta: 3:26:50  iter: 2039  total_loss: 0.8589  loss_cls: 0.07279  loss_box_reg: 0.3289  loss_mask: 0.2543  loss_rpn_cls: 0.04125  loss_rpn_loc: 0.1439  time: 3.1219  data_time: 0.0335  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:49:27 d2.utils.events]: \u001b[0m eta: 3:25:51  iter: 2059  total_loss: 0.8511  loss_cls: 0.06765  loss_box_reg: 0.322  loss_mask: 0.265  loss_rpn_cls: 0.03959  loss_rpn_loc: 0.1386  time: 3.1222  data_time: 0.0284  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:50:30 d2.utils.events]: \u001b[0m eta: 3:24:48  iter: 2079  total_loss: 0.8434  loss_cls: 0.06806  loss_box_reg: 0.323  loss_mask: 0.2677  loss_rpn_cls: 0.04024  loss_rpn_loc: 0.1424  time: 3.1225  data_time: 0.0345  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:51:33 d2.utils.events]: \u001b[0m eta: 3:23:47  iter: 2099  total_loss: 0.8437  loss_cls: 0.07165  loss_box_reg: 0.331  loss_mask: 0.2538  loss_rpn_cls: 0.03887  loss_rpn_loc: 0.141  time: 3.1229  data_time: 0.0306  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:52:36 d2.utils.events]: \u001b[0m eta: 3:22:43  iter: 2119  total_loss: 0.8721  loss_cls: 0.07183  loss_box_reg: 0.3346  loss_mask: 0.2697  loss_rpn_cls: 0.04081  loss_rpn_loc: 0.142  time: 3.1230  data_time: 0.0324  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:53:39 d2.utils.events]: \u001b[0m eta: 3:21:40  iter: 2139  total_loss: 0.8087  loss_cls: 0.06565  loss_box_reg: 0.3191  loss_mask: 0.2535  loss_rpn_cls: 0.03296  loss_rpn_loc: 0.1348  time: 3.1234  data_time: 0.0360  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:54:42 d2.utils.events]: \u001b[0m eta: 3:20:40  iter: 2159  total_loss: 0.8273  loss_cls: 0.0689  loss_box_reg: 0.3265  loss_mask: 0.263  loss_rpn_cls: 0.03308  loss_rpn_loc: 0.1394  time: 3.1237  data_time: 0.0345  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:55:45 d2.utils.events]: \u001b[0m eta: 3:19:37  iter: 2179  total_loss: 0.7994  loss_cls: 0.06636  loss_box_reg: 0.3079  loss_mask: 0.2417  loss_rpn_cls: 0.03777  loss_rpn_loc: 0.1343  time: 3.1239  data_time: 0.0322  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:56:48 d2.utils.events]: \u001b[0m eta: 3:18:37  iter: 2199  total_loss: 0.7862  loss_cls: 0.0682  loss_box_reg: 0.3033  loss_mask: 0.2476  loss_rpn_cls: 0.03373  loss_rpn_loc: 0.1301  time: 3.1242  data_time: 0.0333  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:57:51 d2.utils.events]: \u001b[0m eta: 3:17:37  iter: 2219  total_loss: 0.8542  loss_cls: 0.06745  loss_box_reg: 0.3104  loss_mask: 0.25  loss_rpn_cls: 0.04136  loss_rpn_loc: 0.1495  time: 3.1245  data_time: 0.0320  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:58:54 d2.utils.events]: \u001b[0m eta: 3:16:35  iter: 2239  total_loss: 0.7786  loss_cls: 0.05979  loss_box_reg: 0.3179  loss_mask: 0.2486  loss_rpn_cls: 0.03267  loss_rpn_loc: 0.1366  time: 3.1245  data_time: 0.0325  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 02:59:57 d2.utils.events]: \u001b[0m eta: 3:15:33  iter: 2259  total_loss: 0.7973  loss_cls: 0.06975  loss_box_reg: 0.3061  loss_mask: 0.2502  loss_rpn_cls: 0.03854  loss_rpn_loc: 0.132  time: 3.1247  data_time: 0.0329  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:00:59 d2.utils.events]: \u001b[0m eta: 3:14:27  iter: 2279  total_loss: 0.8258  loss_cls: 0.06753  loss_box_reg: 0.3205  loss_mask: 0.2632  loss_rpn_cls: 0.0315  loss_rpn_loc: 0.1339  time: 3.1244  data_time: 0.0325  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:02:02 d2.utils.events]: \u001b[0m eta: 3:13:22  iter: 2299  total_loss: 0.8214  loss_cls: 0.06533  loss_box_reg: 0.325  loss_mask: 0.2493  loss_rpn_cls: 0.03976  loss_rpn_loc: 0.1488  time: 3.1247  data_time: 0.0286  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:03:06 d2.utils.events]: \u001b[0m eta: 3:12:21  iter: 2319  total_loss: 0.8461  loss_cls: 0.06965  loss_box_reg: 0.3189  loss_mask: 0.2554  loss_rpn_cls: 0.03563  loss_rpn_loc: 0.1537  time: 3.1252  data_time: 0.0392  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:04:09 d2.utils.events]: \u001b[0m eta: 3:11:19  iter: 2339  total_loss: 0.8291  loss_cls: 0.0781  loss_box_reg: 0.3168  loss_mask: 0.2455  loss_rpn_cls: 0.04259  loss_rpn_loc: 0.1445  time: 3.1256  data_time: 0.0346  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:05:11 d2.utils.events]: \u001b[0m eta: 3:10:17  iter: 2359  total_loss: 0.7757  loss_cls: 0.06166  loss_box_reg: 0.2981  loss_mask: 0.2456  loss_rpn_cls: 0.03319  loss_rpn_loc: 0.136  time: 3.1254  data_time: 0.0279  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:06:14 d2.utils.events]: \u001b[0m eta: 3:09:13  iter: 2379  total_loss: 0.8059  loss_cls: 0.06688  loss_box_reg: 0.3173  loss_mask: 0.2396  loss_rpn_cls: 0.03412  loss_rpn_loc: 0.1362  time: 3.1257  data_time: 0.0315  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:07:17 d2.utils.events]: \u001b[0m eta: 3:08:10  iter: 2399  total_loss: 0.814  loss_cls: 0.06574  loss_box_reg: 0.3178  loss_mask: 0.2499  loss_rpn_cls: 0.03672  loss_rpn_loc: 0.1374  time: 3.1257  data_time: 0.0352  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:08:20 d2.utils.events]: \u001b[0m eta: 3:07:08  iter: 2419  total_loss: 0.8228  loss_cls: 0.06222  loss_box_reg: 0.31  loss_mask: 0.2469  loss_rpn_cls: 0.03479  loss_rpn_loc: 0.1406  time: 3.1258  data_time: 0.0319  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:09:22 d2.utils.events]: \u001b[0m eta: 3:06:04  iter: 2439  total_loss: 0.8421  loss_cls: 0.06379  loss_box_reg: 0.3224  loss_mask: 0.2695  loss_rpn_cls: 0.03905  loss_rpn_loc: 0.139  time: 3.1258  data_time: 0.0302  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:10:25 d2.utils.events]: \u001b[0m eta: 3:05:07  iter: 2459  total_loss: 0.8243  loss_cls: 0.06617  loss_box_reg: 0.3153  loss_mask: 0.2573  loss_rpn_cls: 0.03615  loss_rpn_loc: 0.135  time: 3.1259  data_time: 0.0342  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:11:27 d2.utils.events]: \u001b[0m eta: 3:04:01  iter: 2479  total_loss: 0.7779  loss_cls: 0.05852  loss_box_reg: 0.2984  loss_mask: 0.2528  loss_rpn_cls: 0.03161  loss_rpn_loc: 0.1429  time: 3.1258  data_time: 0.0342  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:12:30 d2.utils.events]: \u001b[0m eta: 3:02:59  iter: 2499  total_loss: 0.7881  loss_cls: 0.05759  loss_box_reg: 0.3133  loss_mask: 0.2587  loss_rpn_cls: 0.03045  loss_rpn_loc: 0.1439  time: 3.1259  data_time: 0.0316  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:13:33 d2.utils.events]: \u001b[0m eta: 3:02:01  iter: 2519  total_loss: 0.7961  loss_cls: 0.0713  loss_box_reg: 0.3101  loss_mask: 0.2469  loss_rpn_cls: 0.03794  loss_rpn_loc: 0.1402  time: 3.1260  data_time: 0.0317  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:14:35 d2.utils.events]: \u001b[0m eta: 3:00:53  iter: 2539  total_loss: 0.8124  loss_cls: 0.06337  loss_box_reg: 0.3136  loss_mask: 0.2545  loss_rpn_cls: 0.03555  loss_rpn_loc: 0.1381  time: 3.1260  data_time: 0.0294  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:15:37 d2.utils.events]: \u001b[0m eta: 2:59:48  iter: 2559  total_loss: 0.7924  loss_cls: 0.06277  loss_box_reg: 0.313  loss_mask: 0.2596  loss_rpn_cls: 0.03365  loss_rpn_loc: 0.1305  time: 3.1259  data_time: 0.0323  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:16:40 d2.utils.events]: \u001b[0m eta: 2:58:49  iter: 2579  total_loss: 0.7588  loss_cls: 0.0583  loss_box_reg: 0.298  loss_mask: 0.2418  loss_rpn_cls: 0.03122  loss_rpn_loc: 0.1277  time: 3.1259  data_time: 0.0299  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:17:42 d2.utils.events]: \u001b[0m eta: 2:57:46  iter: 2599  total_loss: 0.8093  loss_cls: 0.0614  loss_box_reg: 0.3225  loss_mask: 0.2581  loss_rpn_cls: 0.03561  loss_rpn_loc: 0.1403  time: 3.1258  data_time: 0.0305  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:18:45 d2.utils.events]: \u001b[0m eta: 2:56:43  iter: 2619  total_loss: 0.803  loss_cls: 0.06618  loss_box_reg: 0.3116  loss_mask: 0.2383  loss_rpn_cls: 0.03463  loss_rpn_loc: 0.1364  time: 3.1258  data_time: 0.0320  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:19:47 d2.utils.events]: \u001b[0m eta: 2:55:35  iter: 2639  total_loss: 0.7602  loss_cls: 0.05222  loss_box_reg: 0.3069  loss_mask: 0.245  loss_rpn_cls: 0.03348  loss_rpn_loc: 0.1289  time: 3.1255  data_time: 0.0301  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:20:49 d2.utils.events]: \u001b[0m eta: 2:54:30  iter: 2659  total_loss: 0.7992  loss_cls: 0.06112  loss_box_reg: 0.3089  loss_mask: 0.2612  loss_rpn_cls: 0.02932  loss_rpn_loc: 0.1325  time: 3.1254  data_time: 0.0335  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:21:51 d2.utils.events]: \u001b[0m eta: 2:53:25  iter: 2679  total_loss: 0.7864  loss_cls: 0.05934  loss_box_reg: 0.3097  loss_mask: 0.2552  loss_rpn_cls: 0.03202  loss_rpn_loc: 0.1493  time: 3.1253  data_time: 0.0341  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:22:54 d2.utils.events]: \u001b[0m eta: 2:52:22  iter: 2699  total_loss: 0.7747  loss_cls: 0.06094  loss_box_reg: 0.305  loss_mask: 0.256  loss_rpn_cls: 0.03157  loss_rpn_loc: 0.1318  time: 3.1254  data_time: 0.0299  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:23:56 d2.utils.events]: \u001b[0m eta: 2:51:20  iter: 2719  total_loss: 0.8225  loss_cls: 0.06977  loss_box_reg: 0.3264  loss_mask: 0.2541  loss_rpn_cls: 0.03278  loss_rpn_loc: 0.1374  time: 3.1254  data_time: 0.0350  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:25:00 d2.utils.events]: \u001b[0m eta: 2:50:19  iter: 2739  total_loss: 0.812  loss_cls: 0.06464  loss_box_reg: 0.3104  loss_mask: 0.2561  loss_rpn_cls: 0.03495  loss_rpn_loc: 0.1381  time: 3.1257  data_time: 0.0346  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:26:02 d2.utils.events]: \u001b[0m eta: 2:49:18  iter: 2759  total_loss: 0.7576  loss_cls: 0.05474  loss_box_reg: 0.279  loss_mask: 0.2513  loss_rpn_cls: 0.03169  loss_rpn_loc: 0.1278  time: 3.1258  data_time: 0.0331  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:27:05 d2.utils.events]: \u001b[0m eta: 2:48:11  iter: 2779  total_loss: 0.7547  loss_cls: 0.05966  loss_box_reg: 0.2885  loss_mask: 0.2436  loss_rpn_cls: 0.02952  loss_rpn_loc: 0.1293  time: 3.1258  data_time: 0.0350  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:28:08 d2.utils.events]: \u001b[0m eta: 2:47:08  iter: 2799  total_loss: 0.7872  loss_cls: 0.05742  loss_box_reg: 0.3175  loss_mask: 0.2536  loss_rpn_cls: 0.03364  loss_rpn_loc: 0.1262  time: 3.1259  data_time: 0.0316  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:29:10 d2.utils.events]: \u001b[0m eta: 2:46:06  iter: 2819  total_loss: 0.771  loss_cls: 0.0619  loss_box_reg: 0.2995  loss_mask: 0.2481  loss_rpn_cls: 0.03117  loss_rpn_loc: 0.1259  time: 3.1259  data_time: 0.0313  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:30:13 d2.utils.events]: \u001b[0m eta: 2:45:03  iter: 2839  total_loss: 0.795  loss_cls: 0.06484  loss_box_reg: 0.3088  loss_mask: 0.2622  loss_rpn_cls: 0.03383  loss_rpn_loc: 0.1275  time: 3.1258  data_time: 0.0300  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:31:15 d2.utils.events]: \u001b[0m eta: 2:44:03  iter: 2859  total_loss: 0.7414  loss_cls: 0.05682  loss_box_reg: 0.291  loss_mask: 0.2397  loss_rpn_cls: 0.03173  loss_rpn_loc: 0.1257  time: 3.1259  data_time: 0.0317  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:32:19 d2.utils.events]: \u001b[0m eta: 2:43:02  iter: 2879  total_loss: 0.8251  loss_cls: 0.06154  loss_box_reg: 0.3186  loss_mask: 0.2565  loss_rpn_cls: 0.0321  loss_rpn_loc: 0.1352  time: 3.1263  data_time: 0.0332  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:33:22 d2.utils.events]: \u001b[0m eta: 2:41:58  iter: 2899  total_loss: 0.7718  loss_cls: 0.05809  loss_box_reg: 0.2981  loss_mask: 0.2484  loss_rpn_cls: 0.03339  loss_rpn_loc: 0.1252  time: 3.1265  data_time: 0.0322  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:34:25 d2.utils.events]: \u001b[0m eta: 2:40:55  iter: 2919  total_loss: 0.7815  loss_cls: 0.06644  loss_box_reg: 0.3018  loss_mask: 0.2499  loss_rpn_cls: 0.02953  loss_rpn_loc: 0.128  time: 3.1266  data_time: 0.0312  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:34:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 03:35:39 d2.utils.events]: \u001b[0m eta: 2:39:56  iter: 2939  total_loss: 0.7845  loss_cls: 0.06059  loss_box_reg: 0.3075  loss_mask: 0.2461  loss_rpn_cls: 0.03254  loss_rpn_loc: 0.1297  time: 3.1303  data_time: 0.0343  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:36:42 d2.utils.events]: \u001b[0m eta: 2:38:57  iter: 2959  total_loss: 0.7373  loss_cls: 0.05796  loss_box_reg: 0.3031  loss_mask: 0.2481  loss_rpn_cls: 0.03045  loss_rpn_loc: 0.1193  time: 3.1304  data_time: 0.0310  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:37:45 d2.utils.events]: \u001b[0m eta: 2:37:55  iter: 2979  total_loss: 0.7821  loss_cls: 0.06199  loss_box_reg: 0.3103  loss_mask: 0.26  loss_rpn_cls: 0.03205  loss_rpn_loc: 0.1312  time: 3.1307  data_time: 0.0320  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:38:50 d2.utils.events]: \u001b[0m eta: 2:36:55  iter: 2999  total_loss: 0.7844  loss_cls: 0.06588  loss_box_reg: 0.3079  loss_mask: 0.2455  loss_rpn_cls: 0.03775  loss_rpn_loc: 0.1276  time: 3.1309  data_time: 0.0318  lr: 0.005  max_mem: 12869M\n","\u001b[32m[03/04 03:39:54 d2.utils.events]: \u001b[0m eta: 2:35:53  iter: 3019  total_loss: 0.8062  loss_cls: 0.06092  loss_box_reg: 0.3222  loss_mask: 0.2583  loss_rpn_cls: 0.04053  loss_rpn_loc: 0.1297  time: 3.1312  data_time: 0.0363  lr: 0.005  max_mem: 13614M\n","\u001b[32m[03/04 03:40:56 d2.utils.events]: \u001b[0m eta: 2:34:49  iter: 3039  total_loss: 0.7372  loss_cls: 0.05092  loss_box_reg: 0.2879  loss_mask: 0.2415  loss_rpn_cls: 0.0313  loss_rpn_loc: 0.1184  time: 3.1312  data_time: 0.0336  lr: 0.005  max_mem: 13614M\n","\u001b[32m[03/04 03:41:59 d2.utils.events]: \u001b[0m eta: 2:33:48  iter: 3059  total_loss: 0.7878  loss_cls: 0.06067  loss_box_reg: 0.3129  loss_mask: 0.2564  loss_rpn_cls: 0.02898  loss_rpn_loc: 0.1283  time: 3.1313  data_time: 0.0276  lr: 0.005  max_mem: 13614M\n","\u001b[32m[03/04 03:43:01 d2.utils.events]: \u001b[0m eta: 2:32:44  iter: 3079  total_loss: 0.7789  loss_cls: 0.05479  loss_box_reg: 0.314  loss_mask: 0.2474  loss_rpn_cls: 0.02803  loss_rpn_loc: 0.1313  time: 3.1312  data_time: 0.0323  lr: 0.005  max_mem: 13614M\n","\u001b[32m[03/04 03:44:04 d2.utils.events]: \u001b[0m eta: 2:31:40  iter: 3099  total_loss: 0.769  loss_cls: 0.05395  loss_box_reg: 0.3054  loss_mask: 0.2472  loss_rpn_cls: 0.02827  loss_rpn_loc: 0.1291  time: 3.1313  data_time: 0.0314  lr: 0.005  max_mem: 13614M\n","\u001b[32m[03/04 03:45:07 d2.utils.events]: \u001b[0m eta: 2:30:36  iter: 3119  total_loss: 0.7664  loss_cls: 0.05628  loss_box_reg: 0.2968  loss_mask: 0.2438  loss_rpn_cls: 0.02917  loss_rpn_loc: 0.1387  time: 3.1313  data_time: 0.0315  lr: 0.005  max_mem: 13614M\n","\u001b[32m[03/04 03:46:10 d2.utils.events]: \u001b[0m eta: 2:29:34  iter: 3139  total_loss: 0.8227  loss_cls: 0.06457  loss_box_reg: 0.3087  loss_mask: 0.2551  loss_rpn_cls: 0.03837  loss_rpn_loc: 0.134  time: 3.1315  data_time: 0.0326  lr: 0.005  max_mem: 13614M\n","\u001b[32m[03/04 03:47:13 d2.utils.events]: \u001b[0m eta: 2:28:32  iter: 3159  total_loss: 0.7934  loss_cls: 0.06141  loss_box_reg: 0.3111  loss_mask: 0.2626  loss_rpn_cls: 0.02831  loss_rpn_loc: 0.126  time: 3.1316  data_time: 0.0345  lr: 0.005  max_mem: 13614M\n","\u001b[32m[03/04 03:48:16 d2.utils.events]: \u001b[0m eta: 2:27:30  iter: 3179  total_loss: 0.7876  loss_cls: 0.0631  loss_box_reg: 0.3104  loss_mask: 0.2453  loss_rpn_cls: 0.03067  loss_rpn_loc: 0.1303  time: 3.1318  data_time: 0.0323  lr: 0.005  max_mem: 13614M\n","\u001b[32m[03/04 03:49:19 d2.utils.events]: \u001b[0m eta: 2:26:26  iter: 3199  total_loss: 0.752  loss_cls: 0.05395  loss_box_reg: 0.2847  loss_mask: 0.2397  loss_rpn_cls: 0.02684  loss_rpn_loc: 0.1226  time: 3.1317  data_time: 0.0323  lr: 0.005  max_mem: 13614M\n","\u001b[32m[03/04 03:50:22 d2.utils.events]: \u001b[0m eta: 2:25:25  iter: 3219  total_loss: 0.8175  loss_cls: 0.06436  loss_box_reg: 0.3251  loss_mask: 0.259  loss_rpn_cls: 0.03343  loss_rpn_loc: 0.1308  time: 3.1320  data_time: 0.0328  lr: 0.005  max_mem: 13614M\n","\u001b[32m[03/04 03:51:25 d2.utils.events]: \u001b[0m eta: 2:24:21  iter: 3239  total_loss: 0.7936  loss_cls: 0.05393  loss_box_reg: 0.3051  loss_mask: 0.2548  loss_rpn_cls: 0.0288  loss_rpn_loc: 0.1347  time: 3.1321  data_time: 0.0321  lr: 0.005  max_mem: 13614M\n","\u001b[32m[03/04 03:52:29 d2.utils.events]: \u001b[0m eta: 2:23:20  iter: 3259  total_loss: 0.7769  loss_cls: 0.05503  loss_box_reg: 0.3041  loss_mask: 0.2475  loss_rpn_cls: 0.02844  loss_rpn_loc: 0.1273  time: 3.1324  data_time: 0.0328  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 03:53:32 d2.utils.events]: \u001b[0m eta: 2:22:22  iter: 3279  total_loss: 0.8022  loss_cls: 0.06105  loss_box_reg: 0.303  loss_mask: 0.2569  loss_rpn_cls: 0.03081  loss_rpn_loc: 0.1321  time: 3.1326  data_time: 0.0373  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 03:54:35 d2.utils.events]: \u001b[0m eta: 2:21:22  iter: 3299  total_loss: 0.768  loss_cls: 0.05414  loss_box_reg: 0.2989  loss_mask: 0.2534  loss_rpn_cls: 0.0308  loss_rpn_loc: 0.1334  time: 3.1327  data_time: 0.0327  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 03:55:39 d2.utils.events]: \u001b[0m eta: 2:20:18  iter: 3319  total_loss: 0.7533  loss_cls: 0.05785  loss_box_reg: 0.2981  loss_mask: 0.2445  loss_rpn_cls: 0.02822  loss_rpn_loc: 0.1257  time: 3.1329  data_time: 0.0338  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 03:56:42 d2.utils.events]: \u001b[0m eta: 2:19:15  iter: 3339  total_loss: 0.7906  loss_cls: 0.06352  loss_box_reg: 0.3085  loss_mask: 0.2604  loss_rpn_cls: 0.03109  loss_rpn_loc: 0.1236  time: 3.1331  data_time: 0.0333  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 03:57:45 d2.utils.events]: \u001b[0m eta: 2:18:13  iter: 3359  total_loss: 0.7734  loss_cls: 0.05707  loss_box_reg: 0.3031  loss_mask: 0.2426  loss_rpn_cls: 0.03246  loss_rpn_loc: 0.1196  time: 3.1332  data_time: 0.0336  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 03:58:49 d2.utils.events]: \u001b[0m eta: 2:17:16  iter: 3379  total_loss: 0.797  loss_cls: 0.06405  loss_box_reg: 0.3175  loss_mask: 0.2504  loss_rpn_cls: 0.02934  loss_rpn_loc: 0.1261  time: 3.1336  data_time: 0.0343  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 03:59:53 d2.utils.events]: \u001b[0m eta: 2:16:18  iter: 3399  total_loss: 0.8  loss_cls: 0.05986  loss_box_reg: 0.3121  loss_mask: 0.2566  loss_rpn_cls: 0.02836  loss_rpn_loc: 0.1224  time: 3.1340  data_time: 0.0319  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:00:56 d2.utils.events]: \u001b[0m eta: 2:15:15  iter: 3419  total_loss: 0.7248  loss_cls: 0.05661  loss_box_reg: 0.2901  loss_mask: 0.2341  loss_rpn_cls: 0.02853  loss_rpn_loc: 0.1237  time: 3.1341  data_time: 0.0302  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:02:00 d2.utils.events]: \u001b[0m eta: 2:14:15  iter: 3439  total_loss: 0.7465  loss_cls: 0.05446  loss_box_reg: 0.2991  loss_mask: 0.2518  loss_rpn_cls: 0.03186  loss_rpn_loc: 0.1191  time: 3.1345  data_time: 0.0371  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:03:04 d2.utils.events]: \u001b[0m eta: 2:13:14  iter: 3459  total_loss: 0.7447  loss_cls: 0.0537  loss_box_reg: 0.2995  loss_mask: 0.244  loss_rpn_cls: 0.02666  loss_rpn_loc: 0.1177  time: 3.1349  data_time: 0.0326  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:04:08 d2.utils.events]: \u001b[0m eta: 2:12:13  iter: 3479  total_loss: 0.8081  loss_cls: 0.06023  loss_box_reg: 0.3132  loss_mask: 0.2593  loss_rpn_cls: 0.03148  loss_rpn_loc: 0.1304  time: 3.1352  data_time: 0.0332  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:05:11 d2.utils.events]: \u001b[0m eta: 2:11:09  iter: 3499  total_loss: 0.7347  loss_cls: 0.05287  loss_box_reg: 0.2903  loss_mask: 0.2324  loss_rpn_cls: 0.02753  loss_rpn_loc: 0.1256  time: 3.1354  data_time: 0.0282  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:06:15 d2.utils.events]: \u001b[0m eta: 2:10:08  iter: 3519  total_loss: 0.7468  loss_cls: 0.05784  loss_box_reg: 0.2941  loss_mask: 0.2416  loss_rpn_cls: 0.02976  loss_rpn_loc: 0.1207  time: 3.1355  data_time: 0.0324  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:07:18 d2.utils.events]: \u001b[0m eta: 2:09:07  iter: 3539  total_loss: 0.8061  loss_cls: 0.05731  loss_box_reg: 0.3105  loss_mask: 0.2599  loss_rpn_cls: 0.03114  loss_rpn_loc: 0.1345  time: 3.1356  data_time: 0.0332  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:08:21 d2.utils.events]: \u001b[0m eta: 2:08:04  iter: 3559  total_loss: 0.8135  loss_cls: 0.0572  loss_box_reg: 0.3128  loss_mask: 0.2617  loss_rpn_cls: 0.02673  loss_rpn_loc: 0.1302  time: 3.1357  data_time: 0.0304  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:09:24 d2.utils.events]: \u001b[0m eta: 2:07:02  iter: 3579  total_loss: 0.7543  loss_cls: 0.05423  loss_box_reg: 0.2922  loss_mask: 0.2458  loss_rpn_cls: 0.03177  loss_rpn_loc: 0.1258  time: 3.1358  data_time: 0.0343  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:10:28 d2.utils.events]: \u001b[0m eta: 2:06:02  iter: 3599  total_loss: 0.7602  loss_cls: 0.05632  loss_box_reg: 0.3055  loss_mask: 0.2423  loss_rpn_cls: 0.02977  loss_rpn_loc: 0.1286  time: 3.1361  data_time: 0.0333  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:11:31 d2.utils.events]: \u001b[0m eta: 2:05:03  iter: 3619  total_loss: 0.7795  loss_cls: 0.06533  loss_box_reg: 0.3076  loss_mask: 0.2439  loss_rpn_cls: 0.03138  loss_rpn_loc: 0.1243  time: 3.1362  data_time: 0.0316  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:12:34 d2.utils.events]: \u001b[0m eta: 2:04:02  iter: 3639  total_loss: 0.7805  loss_cls: 0.05709  loss_box_reg: 0.3015  loss_mask: 0.2446  loss_rpn_cls: 0.03095  loss_rpn_loc: 0.1266  time: 3.1365  data_time: 0.0330  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:13:38 d2.utils.events]: \u001b[0m eta: 2:03:00  iter: 3659  total_loss: 0.746  loss_cls: 0.05606  loss_box_reg: 0.2887  loss_mask: 0.2394  loss_rpn_cls: 0.03126  loss_rpn_loc: 0.1323  time: 3.1366  data_time: 0.0331  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:14:42 d2.utils.events]: \u001b[0m eta: 2:01:59  iter: 3679  total_loss: 0.7809  loss_cls: 0.06023  loss_box_reg: 0.3059  loss_mask: 0.2468  loss_rpn_cls: 0.02979  loss_rpn_loc: 0.127  time: 3.1370  data_time: 0.0353  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:15:45 d2.utils.events]: \u001b[0m eta: 2:00:56  iter: 3699  total_loss: 0.7817  loss_cls: 0.06248  loss_box_reg: 0.2986  loss_mask: 0.2455  loss_rpn_cls: 0.02603  loss_rpn_loc: 0.1405  time: 3.1370  data_time: 0.0364  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:16:48 d2.utils.events]: \u001b[0m eta: 1:59:53  iter: 3719  total_loss: 0.7455  loss_cls: 0.05636  loss_box_reg: 0.2952  loss_mask: 0.2384  loss_rpn_cls: 0.02592  loss_rpn_loc: 0.1263  time: 3.1371  data_time: 0.0342  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:17:51 d2.utils.events]: \u001b[0m eta: 1:58:50  iter: 3739  total_loss: 0.7682  loss_cls: 0.05547  loss_box_reg: 0.2966  loss_mask: 0.2458  loss_rpn_cls: 0.02447  loss_rpn_loc: 0.1244  time: 3.1373  data_time: 0.0310  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:18:54 d2.utils.events]: \u001b[0m eta: 1:57:47  iter: 3759  total_loss: 0.7526  loss_cls: 0.05478  loss_box_reg: 0.2936  loss_mask: 0.2561  loss_rpn_cls: 0.02627  loss_rpn_loc: 0.1212  time: 3.1373  data_time: 0.0326  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:19:57 d2.utils.events]: \u001b[0m eta: 1:56:45  iter: 3779  total_loss: 0.7331  loss_cls: 0.05095  loss_box_reg: 0.2888  loss_mask: 0.2423  loss_rpn_cls: 0.02615  loss_rpn_loc: 0.1199  time: 3.1373  data_time: 0.0341  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:21:00 d2.utils.events]: \u001b[0m eta: 1:55:42  iter: 3799  total_loss: 0.7519  loss_cls: 0.05417  loss_box_reg: 0.2966  loss_mask: 0.2427  loss_rpn_cls: 0.02839  loss_rpn_loc: 0.1273  time: 3.1374  data_time: 0.0315  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:22:04 d2.utils.events]: \u001b[0m eta: 1:54:40  iter: 3819  total_loss: 0.7489  loss_cls: 0.05518  loss_box_reg: 0.2921  loss_mask: 0.2538  loss_rpn_cls: 0.02291  loss_rpn_loc: 0.1243  time: 3.1377  data_time: 0.0333  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:23:07 d2.utils.events]: \u001b[0m eta: 1:53:38  iter: 3839  total_loss: 0.7361  loss_cls: 0.05392  loss_box_reg: 0.2909  loss_mask: 0.2383  loss_rpn_cls: 0.02519  loss_rpn_loc: 0.1174  time: 3.1379  data_time: 0.0342  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:24:10 d2.utils.events]: \u001b[0m eta: 1:52:38  iter: 3859  total_loss: 0.7698  loss_cls: 0.06073  loss_box_reg: 0.3003  loss_mask: 0.2491  loss_rpn_cls: 0.02834  loss_rpn_loc: 0.1267  time: 3.1380  data_time: 0.0354  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:25:14 d2.utils.events]: \u001b[0m eta: 1:51:38  iter: 3879  total_loss: 0.7484  loss_cls: 0.05733  loss_box_reg: 0.2963  loss_mask: 0.2503  loss_rpn_cls: 0.02428  loss_rpn_loc: 0.1173  time: 3.1383  data_time: 0.0686  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:26:18 d2.utils.events]: \u001b[0m eta: 1:50:36  iter: 3899  total_loss: 0.7686  loss_cls: 0.06366  loss_box_reg: 0.2959  loss_mask: 0.2471  loss_rpn_cls: 0.03148  loss_rpn_loc: 0.1189  time: 3.1384  data_time: 0.0346  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:27:21 d2.utils.events]: \u001b[0m eta: 1:49:33  iter: 3919  total_loss: 0.7544  loss_cls: 0.05434  loss_box_reg: 0.3074  loss_mask: 0.2431  loss_rpn_cls: 0.02778  loss_rpn_loc: 0.125  time: 3.1387  data_time: 0.0317  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:28:25 d2.utils.events]: \u001b[0m eta: 1:48:29  iter: 3939  total_loss: 0.7999  loss_cls: 0.06078  loss_box_reg: 0.3094  loss_mask: 0.2604  loss_rpn_cls: 0.03317  loss_rpn_loc: 0.1312  time: 3.1390  data_time: 0.0682  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:29:28 d2.utils.events]: \u001b[0m eta: 1:47:26  iter: 3959  total_loss: 0.7082  loss_cls: 0.05237  loss_box_reg: 0.2919  loss_mask: 0.2378  loss_rpn_cls: 0.02298  loss_rpn_loc: 0.1162  time: 3.1390  data_time: 0.0320  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:30:32 d2.utils.events]: \u001b[0m eta: 1:46:23  iter: 3979  total_loss: 0.736  loss_cls: 0.05414  loss_box_reg: 0.2973  loss_mask: 0.2446  loss_rpn_cls: 0.02588  loss_rpn_loc: 0.1172  time: 3.1392  data_time: 0.0349  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:31:37 d2.utils.events]: \u001b[0m eta: 1:45:20  iter: 3999  total_loss: 0.7338  loss_cls: 0.05725  loss_box_reg: 0.2911  loss_mask: 0.2467  loss_rpn_cls: 0.02583  loss_rpn_loc: 0.1147  time: 3.1393  data_time: 0.0340  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:32:40 d2.utils.events]: \u001b[0m eta: 1:44:17  iter: 4019  total_loss: 0.7512  loss_cls: 0.0573  loss_box_reg: 0.291  loss_mask: 0.2403  loss_rpn_cls: 0.02435  loss_rpn_loc: 0.1219  time: 3.1395  data_time: 0.0341  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:33:44 d2.utils.events]: \u001b[0m eta: 1:43:16  iter: 4039  total_loss: 0.7513  loss_cls: 0.05068  loss_box_reg: 0.2863  loss_mask: 0.257  loss_rpn_cls: 0.029  loss_rpn_loc: 0.1234  time: 3.1398  data_time: 0.0313  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:34:48 d2.utils.events]: \u001b[0m eta: 1:42:15  iter: 4059  total_loss: 0.7722  loss_cls: 0.05926  loss_box_reg: 0.3191  loss_mask: 0.2436  loss_rpn_cls: 0.02742  loss_rpn_loc: 0.132  time: 3.1399  data_time: 0.0325  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:35:51 d2.utils.events]: \u001b[0m eta: 1:41:16  iter: 4079  total_loss: 0.7742  loss_cls: 0.06175  loss_box_reg: 0.2973  loss_mask: 0.2479  loss_rpn_cls: 0.03115  loss_rpn_loc: 0.1283  time: 3.1400  data_time: 0.0308  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:36:54 d2.utils.events]: \u001b[0m eta: 1:40:09  iter: 4099  total_loss: 0.7231  loss_cls: 0.04978  loss_box_reg: 0.2864  loss_mask: 0.2396  loss_rpn_cls: 0.02199  loss_rpn_loc: 0.1231  time: 3.1400  data_time: 0.0327  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:37:57 d2.utils.events]: \u001b[0m eta: 1:39:05  iter: 4119  total_loss: 0.7479  loss_cls: 0.05696  loss_box_reg: 0.3028  loss_mask: 0.2426  loss_rpn_cls: 0.02642  loss_rpn_loc: 0.1215  time: 3.1401  data_time: 0.0331  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:39:00 d2.utils.events]: \u001b[0m eta: 1:38:02  iter: 4139  total_loss: 0.7421  loss_cls: 0.05353  loss_box_reg: 0.2834  loss_mask: 0.2455  loss_rpn_cls: 0.02734  loss_rpn_loc: 0.1291  time: 3.1402  data_time: 0.0332  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:40:03 d2.utils.events]: \u001b[0m eta: 1:37:03  iter: 4159  total_loss: 0.755  loss_cls: 0.05637  loss_box_reg: 0.2963  loss_mask: 0.251  loss_rpn_cls: 0.02768  loss_rpn_loc: 0.1233  time: 3.1403  data_time: 0.0343  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:41:06 d2.utils.events]: \u001b[0m eta: 1:36:01  iter: 4179  total_loss: 0.7426  loss_cls: 0.05397  loss_box_reg: 0.2853  loss_mask: 0.2503  loss_rpn_cls: 0.02393  loss_rpn_loc: 0.1215  time: 3.1404  data_time: 0.0345  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:42:09 d2.utils.events]: \u001b[0m eta: 1:34:59  iter: 4199  total_loss: 0.7723  loss_cls: 0.05827  loss_box_reg: 0.3099  loss_mask: 0.2503  loss_rpn_cls: 0.02718  loss_rpn_loc: 0.1251  time: 3.1404  data_time: 0.0301  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:43:13 d2.utils.events]: \u001b[0m eta: 1:33:53  iter: 4219  total_loss: 0.7458  loss_cls: 0.05149  loss_box_reg: 0.3026  loss_mask: 0.244  loss_rpn_cls: 0.02597  loss_rpn_loc: 0.1234  time: 3.1405  data_time: 0.0297  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:44:16 d2.utils.events]: \u001b[0m eta: 1:32:49  iter: 4239  total_loss: 0.757  loss_cls: 0.05506  loss_box_reg: 0.2952  loss_mask: 0.2426  loss_rpn_cls: 0.02973  loss_rpn_loc: 0.1242  time: 3.1405  data_time: 0.0330  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:45:19 d2.utils.events]: \u001b[0m eta: 1:31:46  iter: 4259  total_loss: 0.7602  loss_cls: 0.05292  loss_box_reg: 0.2986  loss_mask: 0.2505  loss_rpn_cls: 0.02611  loss_rpn_loc: 0.1177  time: 3.1408  data_time: 0.0381  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:46:23 d2.utils.events]: \u001b[0m eta: 1:30:41  iter: 4279  total_loss: 0.7659  loss_cls: 0.05745  loss_box_reg: 0.3102  loss_mask: 0.2502  loss_rpn_cls: 0.02693  loss_rpn_loc: 0.1185  time: 3.1409  data_time: 0.0356  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:47:26 d2.utils.events]: \u001b[0m eta: 1:29:42  iter: 4299  total_loss: 0.7339  loss_cls: 0.06086  loss_box_reg: 0.2908  loss_mask: 0.247  loss_rpn_cls: 0.02336  loss_rpn_loc: 0.1204  time: 3.1411  data_time: 0.0328  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:48:30 d2.utils.events]: \u001b[0m eta: 1:28:38  iter: 4319  total_loss: 0.78  loss_cls: 0.06247  loss_box_reg: 0.2982  loss_mask: 0.2541  loss_rpn_cls: 0.02803  loss_rpn_loc: 0.1246  time: 3.1412  data_time: 0.0299  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:49:33 d2.utils.events]: \u001b[0m eta: 1:27:36  iter: 4339  total_loss: 0.7201  loss_cls: 0.0558  loss_box_reg: 0.2807  loss_mask: 0.2431  loss_rpn_cls: 0.02523  loss_rpn_loc: 0.1194  time: 3.1412  data_time: 0.0314  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:50:36 d2.utils.events]: \u001b[0m eta: 1:26:34  iter: 4359  total_loss: 0.7466  loss_cls: 0.05839  loss_box_reg: 0.2995  loss_mask: 0.245  loss_rpn_cls: 0.02498  loss_rpn_loc: 0.1179  time: 3.1413  data_time: 0.0353  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:51:34 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 04:51:48 d2.utils.events]: \u001b[0m eta: 1:25:31  iter: 4379  total_loss: 0.7549  loss_cls: 0.05314  loss_box_reg: 0.3016  loss_mask: 0.2527  loss_rpn_cls: 0.02054  loss_rpn_loc: 0.1142  time: 3.1435  data_time: 0.0312  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:52:51 d2.utils.events]: \u001b[0m eta: 1:24:27  iter: 4399  total_loss: 0.743  loss_cls: 0.04922  loss_box_reg: 0.2996  loss_mask: 0.2488  loss_rpn_cls: 0.0256  loss_rpn_loc: 0.1218  time: 3.1436  data_time: 0.0314  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:53:54 d2.utils.events]: \u001b[0m eta: 1:23:22  iter: 4419  total_loss: 0.7443  loss_cls: 0.05132  loss_box_reg: 0.2957  loss_mask: 0.247  loss_rpn_cls: 0.02299  loss_rpn_loc: 0.1247  time: 3.1435  data_time: 0.0329  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:54:58 d2.utils.events]: \u001b[0m eta: 1:22:18  iter: 4439  total_loss: 0.7181  loss_cls: 0.0508  loss_box_reg: 0.2881  loss_mask: 0.2459  loss_rpn_cls: 0.02265  loss_rpn_loc: 0.1212  time: 3.1437  data_time: 0.0317  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:56:02 d2.utils.events]: \u001b[0m eta: 1:21:10  iter: 4459  total_loss: 0.762  loss_cls: 0.05613  loss_box_reg: 0.3005  loss_mask: 0.2512  loss_rpn_cls: 0.02421  loss_rpn_loc: 0.1226  time: 3.1439  data_time: 0.0338  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:57:05 d2.utils.events]: \u001b[0m eta: 1:20:07  iter: 4479  total_loss: 0.7301  loss_cls: 0.05516  loss_box_reg: 0.2944  loss_mask: 0.2405  loss_rpn_cls: 0.02271  loss_rpn_loc: 0.1178  time: 3.1441  data_time: 0.0307  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:57:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 04:58:18 d2.utils.events]: \u001b[0m eta: 1:19:10  iter: 4499  total_loss: 0.7335  loss_cls: 0.05187  loss_box_reg: 0.2905  loss_mask: 0.2358  loss_rpn_cls: 0.02497  loss_rpn_loc: 0.1194  time: 3.1462  data_time: 0.0374  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 04:59:21 d2.utils.events]: \u001b[0m eta: 1:18:07  iter: 4519  total_loss: 0.7759  loss_cls: 0.06211  loss_box_reg: 0.3134  loss_mask: 0.2575  loss_rpn_cls: 0.02812  loss_rpn_loc: 0.1233  time: 3.1463  data_time: 0.0316  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:00:25 d2.utils.events]: \u001b[0m eta: 1:17:07  iter: 4539  total_loss: 0.714  loss_cls: 0.0525  loss_box_reg: 0.2888  loss_mask: 0.2328  loss_rpn_cls: 0.02289  loss_rpn_loc: 0.1162  time: 3.1466  data_time: 0.0313  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:01:29 d2.utils.events]: \u001b[0m eta: 1:16:04  iter: 4559  total_loss: 0.7651  loss_cls: 0.06009  loss_box_reg: 0.2933  loss_mask: 0.2546  loss_rpn_cls: 0.0287  loss_rpn_loc: 0.1298  time: 3.1468  data_time: 0.0361  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:02:33 d2.utils.events]: \u001b[0m eta: 1:15:00  iter: 4579  total_loss: 0.7504  loss_cls: 0.05467  loss_box_reg: 0.295  loss_mask: 0.247  loss_rpn_cls: 0.02448  loss_rpn_loc: 0.1213  time: 3.1470  data_time: 0.0340  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:03:37 d2.utils.events]: \u001b[0m eta: 1:13:56  iter: 4599  total_loss: 0.7413  loss_cls: 0.05533  loss_box_reg: 0.2829  loss_mask: 0.2447  loss_rpn_cls: 0.02673  loss_rpn_loc: 0.1199  time: 3.1471  data_time: 0.0343  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:04:40 d2.utils.events]: \u001b[0m eta: 1:12:52  iter: 4619  total_loss: 0.7276  loss_cls: 0.05049  loss_box_reg: 0.2896  loss_mask: 0.2465  loss_rpn_cls: 0.0257  loss_rpn_loc: 0.1196  time: 3.1472  data_time: 0.0344  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:05:43 d2.utils.events]: \u001b[0m eta: 1:11:47  iter: 4639  total_loss: 0.722  loss_cls: 0.04868  loss_box_reg: 0.287  loss_mask: 0.2388  loss_rpn_cls: 0.02245  loss_rpn_loc: 0.114  time: 3.1473  data_time: 0.0338  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:06:47 d2.utils.events]: \u001b[0m eta: 1:10:44  iter: 4659  total_loss: 0.727  loss_cls: 0.05059  loss_box_reg: 0.294  loss_mask: 0.2344  loss_rpn_cls: 0.02355  loss_rpn_loc: 0.1121  time: 3.1475  data_time: 0.0332  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:07:51 d2.utils.events]: \u001b[0m eta: 1:09:38  iter: 4679  total_loss: 0.7501  loss_cls: 0.05457  loss_box_reg: 0.3005  loss_mask: 0.2474  loss_rpn_cls: 0.02485  loss_rpn_loc: 0.1204  time: 3.1476  data_time: 0.0331  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:08:54 d2.utils.events]: \u001b[0m eta: 1:08:35  iter: 4699  total_loss: 0.7067  loss_cls: 0.04767  loss_box_reg: 0.2802  loss_mask: 0.2477  loss_rpn_cls: 0.02476  loss_rpn_loc: 0.1141  time: 3.1476  data_time: 0.0347  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:09:56 d2.utils.events]: \u001b[0m eta: 1:07:31  iter: 4719  total_loss: 0.7185  loss_cls: 0.04888  loss_box_reg: 0.2893  loss_mask: 0.2415  loss_rpn_cls: 0.02783  loss_rpn_loc: 0.123  time: 3.1476  data_time: 0.0326  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:11:00 d2.utils.events]: \u001b[0m eta: 1:06:28  iter: 4739  total_loss: 0.72  loss_cls: 0.04797  loss_box_reg: 0.2868  loss_mask: 0.2574  loss_rpn_cls: 0.02436  loss_rpn_loc: 0.1181  time: 3.1476  data_time: 0.0301  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:12:03 d2.utils.events]: \u001b[0m eta: 1:05:25  iter: 4759  total_loss: 0.7193  loss_cls: 0.05277  loss_box_reg: 0.2904  loss_mask: 0.2311  loss_rpn_cls: 0.02224  loss_rpn_loc: 0.1172  time: 3.1476  data_time: 0.0336  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:13:06 d2.utils.events]: \u001b[0m eta: 1:04:22  iter: 4779  total_loss: 0.7554  loss_cls: 0.05368  loss_box_reg: 0.2949  loss_mask: 0.2545  loss_rpn_cls: 0.02262  loss_rpn_loc: 0.1184  time: 3.1477  data_time: 0.0327  lr: 0.005  max_mem: 13806M\n","\u001b[32m[03/04 05:14:11 d2.utils.events]: \u001b[0m eta: 1:03:19  iter: 4799  total_loss: 0.757  loss_cls: 0.05251  loss_box_reg: 0.2963  loss_mask: 0.2426  loss_rpn_cls: 0.0259  loss_rpn_loc: 0.1197  time: 3.1481  data_time: 0.0352  lr: 0.005  max_mem: 13819M\n","\u001b[32m[03/04 05:15:14 d2.utils.events]: \u001b[0m eta: 1:02:15  iter: 4819  total_loss: 0.7249  loss_cls: 0.05059  loss_box_reg: 0.2799  loss_mask: 0.2386  loss_rpn_cls: 0.02339  loss_rpn_loc: 0.1194  time: 3.1481  data_time: 0.0351  lr: 0.005  max_mem: 13819M\n","\u001b[32m[03/04 05:16:18 d2.utils.events]: \u001b[0m eta: 1:01:12  iter: 4839  total_loss: 0.7449  loss_cls: 0.05254  loss_box_reg: 0.3005  loss_mask: 0.2516  loss_rpn_cls: 0.02521  loss_rpn_loc: 0.1154  time: 3.1484  data_time: 0.0342  lr: 0.005  max_mem: 13819M\n","\u001b[32m[03/04 05:17:22 d2.utils.events]: \u001b[0m eta: 1:00:09  iter: 4859  total_loss: 0.7206  loss_cls: 0.05161  loss_box_reg: 0.2833  loss_mask: 0.2442  loss_rpn_cls: 0.02298  loss_rpn_loc: 0.1137  time: 3.1485  data_time: 0.0329  lr: 0.005  max_mem: 13819M\n","\u001b[32m[03/04 05:18:25 d2.utils.events]: \u001b[0m eta: 0:59:07  iter: 4879  total_loss: 0.7017  loss_cls: 0.05529  loss_box_reg: 0.2834  loss_mask: 0.2392  loss_rpn_cls: 0.02467  loss_rpn_loc: 0.1169  time: 3.1486  data_time: 0.0322  lr: 0.005  max_mem: 13819M\n","\u001b[32m[03/04 05:19:29 d2.utils.events]: \u001b[0m eta: 0:58:03  iter: 4899  total_loss: 0.7452  loss_cls: 0.05175  loss_box_reg: 0.2927  loss_mask: 0.248  loss_rpn_cls: 0.02351  loss_rpn_loc: 0.1198  time: 3.1487  data_time: 0.0343  lr: 0.005  max_mem: 13819M\n","\u001b[32m[03/04 05:20:32 d2.utils.events]: \u001b[0m eta: 0:57:00  iter: 4919  total_loss: 0.7055  loss_cls: 0.05049  loss_box_reg: 0.2842  loss_mask: 0.245  loss_rpn_cls: 0.02333  loss_rpn_loc: 0.1148  time: 3.1487  data_time: 0.0381  lr: 0.005  max_mem: 13819M\n","\u001b[32m[03/04 05:21:35 d2.utils.events]: \u001b[0m eta: 0:55:57  iter: 4939  total_loss: 0.6694  loss_cls: 0.04564  loss_box_reg: 0.2694  loss_mask: 0.2334  loss_rpn_cls: 0.02071  loss_rpn_loc: 0.1127  time: 3.1488  data_time: 0.0309  lr: 0.005  max_mem: 13819M\n","\u001b[32m[03/04 05:22:39 d2.utils.events]: \u001b[0m eta: 0:54:53  iter: 4959  total_loss: 0.7493  loss_cls: 0.05175  loss_box_reg: 0.3003  loss_mask: 0.2449  loss_rpn_cls: 0.02465  loss_rpn_loc: 0.1172  time: 3.1489  data_time: 0.0371  lr: 0.005  max_mem: 13819M\n","\u001b[32m[03/04 05:23:43 d2.utils.events]: \u001b[0m eta: 0:53:50  iter: 4979  total_loss: 0.7212  loss_cls: 0.05141  loss_box_reg: 0.2862  loss_mask: 0.2358  loss_rpn_cls: 0.02082  loss_rpn_loc: 0.1167  time: 3.1491  data_time: 0.0306  lr: 0.005  max_mem: 13819M\n","\u001b[32m[03/04 05:24:48 d2.utils.events]: \u001b[0m eta: 0:52:47  iter: 4999  total_loss: 0.7288  loss_cls: 0.0513  loss_box_reg: 0.2853  loss_mask: 0.2481  loss_rpn_cls: 0.02386  loss_rpn_loc: 0.1264  time: 3.1492  data_time: 0.0324  lr: 0.005  max_mem: 13819M\n","\u001b[32m[03/04 05:25:51 d2.utils.events]: \u001b[0m eta: 0:51:43  iter: 5019  total_loss: 0.747  loss_cls: 0.05278  loss_box_reg: 0.301  loss_mask: 0.2481  loss_rpn_cls: 0.02689  loss_rpn_loc: 0.1161  time: 3.1493  data_time: 0.0335  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:26:56 d2.utils.events]: \u001b[0m eta: 0:50:40  iter: 5039  total_loss: 0.6931  loss_cls: 0.0471  loss_box_reg: 0.2745  loss_mask: 0.2403  loss_rpn_cls: 0.0226  loss_rpn_loc: 0.1091  time: 3.1496  data_time: 0.0373  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:27:59 d2.utils.events]: \u001b[0m eta: 0:49:38  iter: 5059  total_loss: 0.7095  loss_cls: 0.05411  loss_box_reg: 0.2882  loss_mask: 0.2471  loss_rpn_cls: 0.02138  loss_rpn_loc: 0.1063  time: 3.1496  data_time: 0.0292  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:29:02 d2.utils.events]: \u001b[0m eta: 0:48:34  iter: 5079  total_loss: 0.7066  loss_cls: 0.04939  loss_box_reg: 0.2845  loss_mask: 0.231  loss_rpn_cls: 0.01802  loss_rpn_loc: 0.1117  time: 3.1497  data_time: 0.0364  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:30:05 d2.utils.events]: \u001b[0m eta: 0:47:31  iter: 5099  total_loss: 0.6868  loss_cls: 0.05252  loss_box_reg: 0.2715  loss_mask: 0.2324  loss_rpn_cls: 0.02522  loss_rpn_loc: 0.1057  time: 3.1497  data_time: 0.0325  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:31:08 d2.utils.events]: \u001b[0m eta: 0:46:29  iter: 5119  total_loss: 0.702  loss_cls: 0.04682  loss_box_reg: 0.2776  loss_mask: 0.2365  loss_rpn_cls: 0.02645  loss_rpn_loc: 0.1069  time: 3.1497  data_time: 0.0324  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:32:12 d2.utils.events]: \u001b[0m eta: 0:45:25  iter: 5139  total_loss: 0.7214  loss_cls: 0.05662  loss_box_reg: 0.2948  loss_mask: 0.2452  loss_rpn_cls: 0.02291  loss_rpn_loc: 0.1026  time: 3.1498  data_time: 0.0379  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:33:16 d2.utils.events]: \u001b[0m eta: 0:44:22  iter: 5159  total_loss: 0.7023  loss_cls: 0.04748  loss_box_reg: 0.2808  loss_mask: 0.2391  loss_rpn_cls: 0.01968  loss_rpn_loc: 0.1069  time: 3.1499  data_time: 0.0312  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:34:18 d2.utils.events]: \u001b[0m eta: 0:43:18  iter: 5179  total_loss: 0.7097  loss_cls: 0.04895  loss_box_reg: 0.2801  loss_mask: 0.237  loss_rpn_cls: 0.02117  loss_rpn_loc: 0.1064  time: 3.1499  data_time: 0.0354  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:35:22 d2.utils.events]: \u001b[0m eta: 0:42:15  iter: 5199  total_loss: 0.7188  loss_cls: 0.04984  loss_box_reg: 0.2973  loss_mask: 0.2422  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.1099  time: 3.1500  data_time: 0.0320  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:36:25 d2.utils.events]: \u001b[0m eta: 0:41:12  iter: 5219  total_loss: 0.7108  loss_cls: 0.04459  loss_box_reg: 0.2809  loss_mask: 0.2388  loss_rpn_cls: 0.0204  loss_rpn_loc: 0.1107  time: 3.1500  data_time: 0.0340  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:37:28 d2.utils.events]: \u001b[0m eta: 0:40:08  iter: 5239  total_loss: 0.704  loss_cls: 0.04602  loss_box_reg: 0.2775  loss_mask: 0.2475  loss_rpn_cls: 0.02057  loss_rpn_loc: 0.1119  time: 3.1500  data_time: 0.0277  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:38:32 d2.utils.events]: \u001b[0m eta: 0:39:04  iter: 5259  total_loss: 0.7164  loss_cls: 0.05401  loss_box_reg: 0.2919  loss_mask: 0.2417  loss_rpn_cls: 0.02087  loss_rpn_loc: 0.1084  time: 3.1502  data_time: 0.0335  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:39:35 d2.utils.events]: \u001b[0m eta: 0:38:02  iter: 5279  total_loss: 0.6949  loss_cls: 0.05022  loss_box_reg: 0.2849  loss_mask: 0.2376  loss_rpn_cls: 0.02109  loss_rpn_loc: 0.1054  time: 3.1502  data_time: 0.0350  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:40:39 d2.utils.events]: \u001b[0m eta: 0:36:58  iter: 5299  total_loss: 0.7042  loss_cls: 0.05196  loss_box_reg: 0.2903  loss_mask: 0.244  loss_rpn_cls: 0.01995  loss_rpn_loc: 0.1072  time: 3.1503  data_time: 0.0335  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:41:43 d2.utils.events]: \u001b[0m eta: 0:35:56  iter: 5319  total_loss: 0.7038  loss_cls: 0.04786  loss_box_reg: 0.2855  loss_mask: 0.2397  loss_rpn_cls: 0.02516  loss_rpn_loc: 0.1095  time: 3.1506  data_time: 0.0342  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:42:46 d2.utils.events]: \u001b[0m eta: 0:34:52  iter: 5339  total_loss: 0.6642  loss_cls: 0.04461  loss_box_reg: 0.2787  loss_mask: 0.2331  loss_rpn_cls: 0.01858  loss_rpn_loc: 0.1035  time: 3.1505  data_time: 0.0315  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:43:49 d2.utils.events]: \u001b[0m eta: 0:33:49  iter: 5359  total_loss: 0.7133  loss_cls: 0.05118  loss_box_reg: 0.2806  loss_mask: 0.2385  loss_rpn_cls: 0.0191  loss_rpn_loc: 0.1107  time: 3.1506  data_time: 0.0354  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:44:53 d2.utils.events]: \u001b[0m eta: 0:32:46  iter: 5379  total_loss: 0.7066  loss_cls: 0.04586  loss_box_reg: 0.2791  loss_mask: 0.2384  loss_rpn_cls: 0.02392  loss_rpn_loc: 0.1034  time: 3.1507  data_time: 0.0323  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:45:56 d2.utils.events]: \u001b[0m eta: 0:31:43  iter: 5399  total_loss: 0.6963  loss_cls: 0.04676  loss_box_reg: 0.2753  loss_mask: 0.2448  loss_rpn_cls: 0.0197  loss_rpn_loc: 0.1059  time: 3.1507  data_time: 0.0319  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:46:59 d2.utils.events]: \u001b[0m eta: 0:30:39  iter: 5419  total_loss: 0.6766  loss_cls: 0.04452  loss_box_reg: 0.2796  loss_mask: 0.2319  loss_rpn_cls: 0.01795  loss_rpn_loc: 0.1021  time: 3.1507  data_time: 0.0353  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:48:02 d2.utils.events]: \u001b[0m eta: 0:29:35  iter: 5439  total_loss: 0.68  loss_cls: 0.04508  loss_box_reg: 0.2873  loss_mask: 0.2371  loss_rpn_cls: 0.01894  loss_rpn_loc: 0.1001  time: 3.1507  data_time: 0.0286  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:49:05 d2.utils.events]: \u001b[0m eta: 0:28:31  iter: 5459  total_loss: 0.7279  loss_cls: 0.04888  loss_box_reg: 0.2882  loss_mask: 0.248  loss_rpn_cls: 0.02189  loss_rpn_loc: 0.1095  time: 3.1507  data_time: 0.0303  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:50:09 d2.utils.events]: \u001b[0m eta: 0:27:28  iter: 5479  total_loss: 0.7185  loss_cls: 0.05357  loss_box_reg: 0.2813  loss_mask: 0.2408  loss_rpn_cls: 0.01965  loss_rpn_loc: 0.1081  time: 3.1510  data_time: 0.0333  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:51:13 d2.utils.events]: \u001b[0m eta: 0:26:25  iter: 5499  total_loss: 0.7221  loss_cls: 0.05341  loss_box_reg: 0.2868  loss_mask: 0.2446  loss_rpn_cls: 0.02104  loss_rpn_loc: 0.1111  time: 3.1511  data_time: 0.0303  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:52:17 d2.utils.events]: \u001b[0m eta: 0:25:21  iter: 5519  total_loss: 0.7134  loss_cls: 0.04759  loss_box_reg: 0.2898  loss_mask: 0.2395  loss_rpn_cls: 0.01811  loss_rpn_loc: 0.1107  time: 3.1512  data_time: 0.0304  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:53:20 d2.utils.events]: \u001b[0m eta: 0:24:18  iter: 5539  total_loss: 0.7022  loss_cls: 0.04692  loss_box_reg: 0.2821  loss_mask: 0.2372  loss_rpn_cls: 0.01907  loss_rpn_loc: 0.1062  time: 3.1512  data_time: 0.0315  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:54:24 d2.utils.events]: \u001b[0m eta: 0:23:14  iter: 5559  total_loss: 0.7049  loss_cls: 0.05003  loss_box_reg: 0.2749  loss_mask: 0.2345  loss_rpn_cls: 0.02241  loss_rpn_loc: 0.1073  time: 3.1514  data_time: 0.0342  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:55:27 d2.utils.events]: \u001b[0m eta: 0:22:11  iter: 5579  total_loss: 0.7288  loss_cls: 0.05607  loss_box_reg: 0.2907  loss_mask: 0.2461  loss_rpn_cls: 0.02108  loss_rpn_loc: 0.1086  time: 3.1515  data_time: 0.0281  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:56:31 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 5599  total_loss: 0.7135  loss_cls: 0.05273  loss_box_reg: 0.2849  loss_mask: 0.2409  loss_rpn_cls: 0.0178  loss_rpn_loc: 0.106  time: 3.1515  data_time: 0.0310  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:57:34 d2.utils.events]: \u001b[0m eta: 0:20:04  iter: 5619  total_loss: 0.6987  loss_cls: 0.04167  loss_box_reg: 0.285  loss_mask: 0.2408  loss_rpn_cls: 0.02053  loss_rpn_loc: 0.1055  time: 3.1515  data_time: 0.0348  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:58:37 d2.utils.events]: \u001b[0m eta: 0:19:01  iter: 5639  total_loss: 0.7045  loss_cls: 0.05051  loss_box_reg: 0.2718  loss_mask: 0.235  loss_rpn_cls: 0.02282  loss_rpn_loc: 0.1133  time: 3.1516  data_time: 0.0351  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 05:59:41 d2.utils.events]: \u001b[0m eta: 0:17:58  iter: 5659  total_loss: 0.7483  loss_cls: 0.05494  loss_box_reg: 0.3043  loss_mask: 0.2476  loss_rpn_cls: 0.02388  loss_rpn_loc: 0.1124  time: 3.1517  data_time: 0.0324  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:00:45 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 5679  total_loss: 0.6996  loss_cls: 0.04827  loss_box_reg: 0.2811  loss_mask: 0.244  loss_rpn_cls: 0.01836  loss_rpn_loc: 0.115  time: 3.1518  data_time: 0.0315  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:01:47 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 5699  total_loss: 0.7077  loss_cls: 0.05069  loss_box_reg: 0.2787  loss_mask: 0.2401  loss_rpn_cls: 0.02256  loss_rpn_loc: 0.1104  time: 3.1518  data_time: 0.0329  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:02:50 d2.utils.events]: \u001b[0m eta: 0:14:48  iter: 5719  total_loss: 0.6731  loss_cls: 0.04407  loss_box_reg: 0.2723  loss_mask: 0.2341  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.1116  time: 3.1517  data_time: 0.0329  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:03:54 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 5739  total_loss: 0.7071  loss_cls: 0.05327  loss_box_reg: 0.2868  loss_mask: 0.2454  loss_rpn_cls: 0.02367  loss_rpn_loc: 0.1054  time: 3.1518  data_time: 0.0333  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:04:57 d2.utils.events]: \u001b[0m eta: 0:12:41  iter: 5759  total_loss: 0.699  loss_cls: 0.04784  loss_box_reg: 0.271  loss_mask: 0.2391  loss_rpn_cls: 0.02291  loss_rpn_loc: 0.1019  time: 3.1519  data_time: 0.0372  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:06:01 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 5779  total_loss: 0.7315  loss_cls: 0.05019  loss_box_reg: 0.2926  loss_mask: 0.239  loss_rpn_cls: 0.02503  loss_rpn_loc: 0.1078  time: 3.1521  data_time: 0.0347  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:07:05 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 5799  total_loss: 0.6967  loss_cls: 0.05072  loss_box_reg: 0.2823  loss_mask: 0.2367  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.1049  time: 3.1522  data_time: 0.0365  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:08:08 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 5819  total_loss: 0.7045  loss_cls: 0.04789  loss_box_reg: 0.2791  loss_mask: 0.2459  loss_rpn_cls: 0.01956  loss_rpn_loc: 0.1051  time: 3.1522  data_time: 0.0312  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:09:11 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 5839  total_loss: 0.6816  loss_cls: 0.04864  loss_box_reg: 0.2646  loss_mask: 0.2273  loss_rpn_cls: 0.02091  loss_rpn_loc: 0.1093  time: 3.1522  data_time: 0.0342  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:10:14 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 5859  total_loss: 0.6512  loss_cls: 0.044  loss_box_reg: 0.2645  loss_mask: 0.2273  loss_rpn_cls: 0.01582  loss_rpn_loc: 0.1028  time: 3.1521  data_time: 0.0333  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:11:17 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 5879  total_loss: 0.7199  loss_cls: 0.04986  loss_box_reg: 0.2896  loss_mask: 0.2416  loss_rpn_cls: 0.01829  loss_rpn_loc: 0.1129  time: 3.1522  data_time: 0.0330  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:12:20 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 5899  total_loss: 0.7017  loss_cls: 0.04772  loss_box_reg: 0.2766  loss_mask: 0.2447  loss_rpn_cls: 0.01873  loss_rpn_loc: 0.1029  time: 3.1522  data_time: 0.0342  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:13:24 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 5919  total_loss: 0.7207  loss_cls: 0.05512  loss_box_reg: 0.2991  loss_mask: 0.2357  loss_rpn_cls: 0.01966  loss_rpn_loc: 0.1096  time: 3.1522  data_time: 0.0355  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:14:27 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 5939  total_loss: 0.6891  loss_cls: 0.05137  loss_box_reg: 0.2766  loss_mask: 0.2426  loss_rpn_cls: 0.01839  loss_rpn_loc: 0.1113  time: 3.1522  data_time: 0.0347  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:15:30 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 5959  total_loss: 0.7133  loss_cls: 0.04836  loss_box_reg: 0.2848  loss_mask: 0.2341  loss_rpn_cls: 0.02433  loss_rpn_loc: 0.1142  time: 3.1522  data_time: 0.0287  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:16:33 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 5979  total_loss: 0.7294  loss_cls: 0.05181  loss_box_reg: 0.2848  loss_mask: 0.2495  loss_rpn_cls: 0.01928  loss_rpn_loc: 0.1099  time: 3.1522  data_time: 0.0339  lr: 0.0025  max_mem: 13819M\n","\u001b[32m[03/04 06:17:43 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:18:14 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:18:35 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:18:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:19:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <detectron2.modeling.matcher.Matcher object at 0x7f2b6567a690> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:19:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:19:33 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:19:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:20:04 detectron2]: \u001b[0mLoss on Validation  done 11/78. 0.0001 s / img. ETA=0:13:22\n","\u001b[32m[03/04 06:20:05 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:20:22 detectron2]: \u001b[0mLoss on Validation  done 12/78. 0.0001 s / img. ETA=0:14:04\n","\u001b[32m[03/04 06:20:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:20:40 detectron2]: \u001b[0mLoss on Validation  done 13/78. 0.0001 s / img. ETA=0:14:29\n","\u001b[32m[03/04 06:20:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:20:52 detectron2]: \u001b[0mLoss on Validation  done 15/78. 0.0001 s / img. ETA=0:12:35\n","\u001b[32m[03/04 06:20:53 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:21:08 detectron2]: \u001b[0mLoss on Validation  done 16/78. 0.0001 s / img. ETA=0:12:45\n","\u001b[32m[03/04 06:21:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:21:40 detectron2]: \u001b[0mLoss on Validation  done 17/78. 0.0001 s / img. ETA=0:14:12\n","\u001b[32m[03/04 06:21:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:22:04 detectron2]: \u001b[0mLoss on Validation  done 18/78. 0.0001 s / img. ETA=0:14:41\n","\u001b[32m[03/04 06:22:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:22:15 detectron2]: \u001b[0mLoss on Validation  done 19/78. 0.0001 s / img. ETA=0:14:13\n","\u001b[32m[03/04 06:22:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:22:29 detectron2]: \u001b[0mLoss on Validation  done 22/78. 0.0001 s / img. ETA=0:11:52\n","\u001b[32m[03/04 06:22:30 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:22:48 detectron2]: \u001b[0mLoss on Validation  done 23/78. 0.0001 s / img. ETA=0:11:59\n","\u001b[32m[03/04 06:22:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:23:06 detectron2]: \u001b[0mLoss on Validation  done 24/78. 0.0001 s / img. ETA=0:12:01\n","\u001b[32m[03/04 06:23:07 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:23:22 detectron2]: \u001b[0mLoss on Validation  done 25/78. 0.0001 s / img. ETA=0:11:53\n","\u001b[32m[03/04 06:23:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:24:00 detectron2]: \u001b[0mLoss on Validation  done 26/78. 0.0001 s / img. ETA=0:12:40\n","\u001b[32m[03/04 06:24:01 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:24:30 detectron2]: \u001b[0mLoss on Validation  done 27/78. 0.0001 s / img. ETA=0:13:01\n","\u001b[32m[03/04 06:24:31 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:24:45 detectron2]: \u001b[0mLoss on Validation  done 29/78. 0.0001 s / img. ETA=0:11:59\n","\u001b[32m[03/04 06:24:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:25:02 detectron2]: \u001b[0mLoss on Validation  done 30/78. 0.0001 s / img. ETA=0:11:49\n","\u001b[32m[03/04 06:25:03 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:25:19 detectron2]: \u001b[0mLoss on Validation  done 31/78. 0.0001 s / img. ETA=0:11:38\n","\u001b[32m[03/04 06:25:22 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:25:48 detectron2]: \u001b[0mLoss on Validation  done 34/78. 0.0001 s / img. ETA=0:10:30\n","\u001b[32m[03/04 06:25:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:26:09 detectron2]: \u001b[0mLoss on Validation  done 36/78. 0.0001 s / img. ETA=0:09:51\n","\u001b[32m[03/04 06:26:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:26:20 detectron2]: \u001b[0mLoss on Validation  done 37/78. 0.0001 s / img. ETA=0:09:33\n","\u001b[32m[03/04 06:26:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:26:37 detectron2]: \u001b[0mLoss on Validation  done 38/78. 0.0001 s / img. ETA=0:09:22\n","\u001b[32m[03/04 06:26:37 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:27:04 detectron2]: \u001b[0mLoss on Validation  done 39/78. 0.0001 s / img. ETA=0:09:23\n","\u001b[32m[03/04 06:27:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:27:27 detectron2]: \u001b[0mLoss on Validation  done 40/78. 0.0001 s / img. ETA=0:09:18\n","\u001b[32m[03/04 06:27:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:27:50 detectron2]: \u001b[0mLoss on Validation  done 41/78. 0.0001 s / img. ETA=0:09:12\n","\u001b[32m[03/04 06:27:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:28:18 detectron2]: \u001b[0mLoss on Validation  done 42/78. 0.0001 s / img. ETA=0:09:09\n","\u001b[32m[03/04 06:28:18 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:28:41 detectron2]: \u001b[0mLoss on Validation  done 43/78. 0.0001 s / img. ETA=0:09:01\n","\u001b[32m[03/04 06:28:41 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:29:09 detectron2]: \u001b[0mLoss on Validation  done 44/78. 0.0001 s / img. ETA=0:08:57\n","\u001b[32m[03/04 06:29:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:29:28 detectron2]: \u001b[0mLoss on Validation  done 45/78. 0.0001 s / img. ETA=0:08:44\n","\u001b[32m[03/04 06:29:29 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:29:56 detectron2]: \u001b[0mLoss on Validation  done 46/78. 0.0001 s / img. ETA=0:08:37\n","\u001b[32m[03/04 06:29:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:30:08 detectron2]: \u001b[0mLoss on Validation  done 47/78. 0.0001 s / img. ETA=0:08:18\n","\u001b[32m[03/04 06:30:08 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:30:50 detectron2]: \u001b[0mLoss on Validation  done 48/78. 0.0001 s / img. ETA=0:08:20\n","\u001b[32m[03/04 06:30:50 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:31:37 detectron2]: \u001b[0mLoss on Validation  done 49/78. 0.0001 s / img. ETA=0:08:24\n","\u001b[32m[03/04 06:31:38 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:31:47 detectron2]: \u001b[0mLoss on Validation  done 50/78. 0.0001 s / img. ETA=0:08:01\n","\u001b[32m[03/04 06:31:48 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:32:24 detectron2]: \u001b[0mLoss on Validation  done 51/78. 0.0001 s / img. ETA=0:07:56\n","\u001b[32m[03/04 06:32:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:32:46 detectron2]: \u001b[0mLoss on Validation  done 52/78. 0.0001 s / img. ETA=0:07:40\n","\u001b[32m[03/04 06:32:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:33:13 detectron2]: \u001b[0mLoss on Validation  done 53/78. 0.0001 s / img. ETA=0:07:28\n","\u001b[32m[03/04 06:33:18 detectron2]: \u001b[0mLoss on Validation  done 57/78. 0.0001 s / img. ETA=0:05:49\n","\u001b[32m[03/04 06:33:20 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:33:56 detectron2]: \u001b[0mLoss on Validation  done 59/78. 0.0001 s / img. ETA=0:05:17\n","\u001b[32m[03/04 06:33:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:34:17 detectron2]: \u001b[0mLoss on Validation  done 60/78. 0.0001 s / img. ETA=0:05:02\n","\u001b[32m[03/04 06:34:19 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:34:34 detectron2]: \u001b[0mLoss on Validation  done 62/78. 0.0001 s / img. ETA=0:04:24\n","\u001b[32m[03/04 06:34:40 detectron2]: \u001b[0mLoss on Validation  done 67/78. 0.0001 s / img. ETA=0:02:48\n","\u001b[32m[03/04 06:34:40 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:34:50 detectron2]: \u001b[0mLoss on Validation  done 68/78. 0.0001 s / img. ETA=0:02:32\n","\u001b[32m[03/04 06:34:51 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:35:04 detectron2]: \u001b[0mLoss on Validation  done 69/78. 0.0001 s / img. ETA=0:02:16\n","\u001b[32m[03/04 06:35:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:35:13 detectron2]: \u001b[0mLoss on Validation  done 70/78. 0.0001 s / img. ETA=0:02:00\n","\u001b[32m[03/04 06:35:15 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:35:23 detectron2]: \u001b[0mLoss on Validation  done 72/78. 0.0001 s / img. ETA=0:01:28\n","\u001b[32m[03/04 06:35:23 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:35:33 detectron2]: \u001b[0mLoss on Validation  done 73/78. 0.0001 s / img. ETA=0:01:13\n","\u001b[32m[03/04 06:35:36 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:35:46 detectron2]: \u001b[0mLoss on Validation  done 75/78. 0.0001 s / img. ETA=0:00:43\n","\u001b[32m[03/04 06:35:47 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:35:58 detectron2]: \u001b[0mLoss on Validation  done 76/78. 0.0001 s / img. ETA=0:00:28\n","\u001b[32m[03/04 06:35:58 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:36:11 detectron2]: \u001b[0mLoss on Validation  done 77/78. 0.0001 s / img. ETA=0:00:14\n","\u001b[32m[03/04 06:36:12 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7f2b8c7aa710> to CPU due to CUDA OOM\n","\u001b[32m[03/04 06:36:21 detectron2]: \u001b[0mLoss on Validation  done 78/78. 0.0001 s / img. ETA=0:00:00\n","\u001b[32m[03/04 06:36:23 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 5999  total_loss: 0.6956  loss_cls: 0.04791  loss_box_reg: 0.2711  loss_mask: 0.23  loss_rpn_cls: 0.01835  loss_rpn_loc: 0.1088  validation_loss: 0.677  time: 3.1522  data_time: 0.0319  lr: 0.0025  max_mem: 14783M\n","\u001b[32m[03/04 06:36:23 d2.engine.hooks]: \u001b[0mOverall training speed: 5998 iterations in 5:15:06 (3.1522 s / it)\n","\u001b[32m[03/04 06:36:23 d2.engine.hooks]: \u001b[0mTotal training time: 5:34:07 (0:19:00 on hooks)\n","\u001b[32m[03/04 06:36:24 d2.data.datasets.coco]: \u001b[0mLoading data/annotations_val.json takes 1.09 seconds.\n","\u001b[32m[03/04 06:36:24 d2.data.datasets.coco]: \u001b[0mLoaded 78 images in COCO format from data/annotations_val.json\n","\u001b[32m[03/04 06:36:24 d2.data.common]: \u001b[0mSerializing 78 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/04 06:36:24 d2.data.common]: \u001b[0mSerialized dataset takes 5.57 MiB\n","\u001b[32m[03/04 06:36:24 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'my_dataset_val' to COCO format ...)\n","\u001b[32m[03/04 06:36:25 d2.data.datasets.coco]: \u001b[0mLoaded 78 images in COCO format from data/annotations_val.json\n","\u001b[32m[03/04 06:36:25 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n","\u001b[32m[03/04 06:36:26 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 78, #annotations: 12716\n","\u001b[32m[03/04 06:36:26 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at 'train_segmentation/checkpoints/my_hope/inference/my_dataset_val_coco_format.json' ...\n","\u001b[32m[03/04 06:36:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 78 images\n","\u001b[32m[03/04 06:40:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/78. 0.5520 s / img. ETA=0:23:47\n","\u001b[32m[03/04 06:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 12/78. 0.5611 s / img. ETA=0:23:50\n","\u001b[32m[03/04 06:41:08 d2.evaluation.evaluator]: \u001b[0mInference done 13/78. 0.5481 s / img. ETA=0:22:57\n","\u001b[32m[03/04 06:41:24 d2.evaluation.evaluator]: \u001b[0mInference done 14/78. 0.5387 s / img. ETA=0:21:55\n","\u001b[32m[03/04 06:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 15/78. 0.5398 s / img. ETA=0:21:40\n","\u001b[32m[03/04 06:41:52 d2.evaluation.evaluator]: \u001b[0mInference done 16/78. 0.5387 s / img. ETA=0:20:02\n","\u001b[32m[03/04 06:42:19 d2.evaluation.evaluator]: \u001b[0mInference done 17/78. 0.5478 s / img. ETA=0:20:22\n","\u001b[32m[03/04 06:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 18/78. 0.5385 s / img. ETA=0:19:35\n","\u001b[32m[03/04 06:42:47 d2.evaluation.evaluator]: \u001b[0mInference done 19/78. 0.5301 s / img. ETA=0:18:51\n","\u001b[32m[03/04 06:43:00 d2.evaluation.evaluator]: \u001b[0mInference done 20/78. 0.5196 s / img. ETA=0:18:07\n","\u001b[32m[03/04 06:43:15 d2.evaluation.evaluator]: \u001b[0mInference done 21/78. 0.5146 s / img. ETA=0:17:35\n","\u001b[32m[03/04 06:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 22/78. 0.5209 s / img. ETA=0:17:41\n","\u001b[32m[03/04 06:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 23/78. 0.5246 s / img. ETA=0:17:36\n","\u001b[32m[03/04 06:44:26 d2.evaluation.evaluator]: \u001b[0mInference done 24/78. 0.5257 s / img. ETA=0:17:22\n","\u001b[32m[03/04 06:44:33 d2.evaluation.evaluator]: \u001b[0mInference done 25/78. 0.5277 s / img. ETA=0:16:32\n","\u001b[32m[03/04 06:45:00 d2.evaluation.evaluator]: \u001b[0mInference done 26/78. 0.5330 s / img. ETA=0:16:34\n","\u001b[32m[03/04 06:45:08 d2.evaluation.evaluator]: \u001b[0mInference done 27/78. 0.5234 s / img. ETA=0:15:47\n","\u001b[32m[03/04 06:45:25 d2.evaluation.evaluator]: \u001b[0mInference done 28/78. 0.5212 s / img. ETA=0:15:26\n","\u001b[32m[03/04 06:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 29/78. 0.5207 s / img. ETA=0:15:09\n","\u001b[32m[03/04 06:46:06 d2.evaluation.evaluator]: \u001b[0mInference done 30/78. 0.5227 s / img. ETA=0:14:57\n","\u001b[32m[03/04 06:46:20 d2.evaluation.evaluator]: \u001b[0mInference done 31/78. 0.5173 s / img. ETA=0:14:29\n","\u001b[32m[03/04 06:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 32/78. 0.5208 s / img. ETA=0:14:22\n","\u001b[32m[03/04 06:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 33/78. 0.5250 s / img. ETA=0:14:14\n","\u001b[32m[03/04 06:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 34/78. 0.5193 s / img. ETA=0:13:46\n","\u001b[32m[03/04 06:47:45 d2.evaluation.evaluator]: \u001b[0mInference done 35/78. 0.5207 s / img. ETA=0:13:31\n","\u001b[32m[03/04 06:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 36/78. 0.5175 s / img. ETA=0:13:06\n","\u001b[32m[03/04 06:48:20 d2.evaluation.evaluator]: \u001b[0mInference done 37/78. 0.5179 s / img. ETA=0:12:49\n","\u001b[32m[03/04 06:48:44 d2.evaluation.evaluator]: \u001b[0mInference done 38/78. 0.5209 s / img. ETA=0:12:38\n"]}],"source":["trainer = Trainer(cfg)\n","trainer.resume_or_load(resume=False)\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPx1emtcwQZo"},"outputs":[],"source":["# NAME = 'v1.2.0'\n","listdir = os.listdir(f'train_segmentation/checkpoints/{NAME}')\n","listdir = list(filter(lambda x:x.endswith('.pth'), listdir))\n","for i, x in enumerate(listdir):\n","    print(f'{i}: {x}')"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Bb4qpfgkZdvQ"},"outputs":[],"source":["#@markdown Predictor\n","from detectron2.data import MetadataCatalog\n","from detectron2.modeling import build_model\n","from detectron2.checkpoint import DetectionCheckpointer\n","\n","\n","class Predictor:\n","    def __init__(self, cfg, test_aug_list):\n","        self.cfg = cfg.clone()  # cfg can be modified by model\n","        self.model = build_model(self.cfg)\n","        self.model.eval()\n","        if len(cfg.DATASETS.TEST):\n","            self.metadata = MetadataCatalog.get(cfg.DATASETS.TEST[0])\n","\n","        checkpointer = DetectionCheckpointer(self.model)\n","        checkpointer.load(cfg.MODEL.WEIGHTS)\n","\n","        self.aug = test_aug_list\n","\n","        self.input_format = cfg.INPUT.FORMAT\n","        assert self.input_format in [\"RGB\", \"BGR\"], self.input_format\n","\n","    def __call__(self, original_image):\n","        with torch.no_grad():  # https://github.com/sphinx-doc/sphinx/issues/4258\n","            # Apply pre-processing to image.\n","            if self.input_format == \"RGB\":\n","                # whether the model expects BGR inputs or RGB\n","                original_image = original_image[:, :, ::-1]\n","            height, width = original_image.shape[:2]\n","            image, transforms = T.apply_transform_gens(test_transform_list, original_image)\n","            image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n","\n","            inputs = {\"image\": image, \"height\": height, \"width\": width}\n","            predictions = self.model([inputs])[0]\n","            return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VNNUdjQdYKjs"},"outputs":[],"source":["# path = f'train_segmentation/checkpoints/{NAME}/' + listdir[INDEX]\n","# cfg.MODEL.PANOPTIC_FPN.COMBINE.OVERLAP_THRESH = 0.25\n","# cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.1\n","\n","# print(path)\n","cfg.merge_from_file('data/train_segmentation/checkpoints/default_v1/config.yml')\n","cfg.MODEL.WEIGHTS = 'data/train_segmentation/checkpoints/default_v1/model_0003999.pth'\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.35\n","cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.4\n","\n","cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 6000 * 5\n","cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 1000 * 5\n","cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n","\n","predictor = Predictor(cfg, test_transform_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7s0SxXZlYKjt"},"outputs":[],"source":["def show_img(id_image_selected):\n","    example = dataset_dicts_val[id_image_selected]\n","    im = cv2.imread(example[\"file_name\"])\n","    outputs = predictor(im)\n","    plt.figure(figsize=(10, 10), dpi=200)\n","    v = Visualizer(im[:, :],\n","                metadata=val_metadata, \n","                scale=1)\n","    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    plt.imshow(v.get_image()[:, :, ::-1])\n","    # plt.axis('off')\n","    plt.show()\n","    del v\n","    del im\n","    del outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lB9U58Lp9GP2"},"outputs":[],"source":["show_img(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWW36i_RcxE9"},"outputs":[],"source":["#@markdown Metrics\n","def intersection_over_union(gt_box, pred_box):\n","    inter_box_top_left = [max(gt_box[0], pred_box[0]), max(gt_box[1], pred_box[1])]\n","    inter_box_bottom_right = [min(gt_box[0]+gt_box[2], pred_box[0]+pred_box[2]), min(gt_box[1]+gt_box[3], pred_box[1]+pred_box[3])]\n","\n","    inter_box_w = inter_box_bottom_right[0] - inter_box_top_left[0]\n","    inter_box_h = inter_box_bottom_right[1] - inter_box_top_left[1]\n","\n","    intersection = inter_box_w * inter_box_h\n","    union = gt_box[2] * gt_box[3] + pred_box[2] * pred_box[3] - intersection\n","    \n","    iou = intersection / union\n","\n","    return iou, intersection, union\n","\n","def f1_loss(y_true, y_pred):\n","    tp = np.sum(y_true & y_pred)\n","    tn = np.sum(~y_true & ~y_pred)\n","    fp = np.sum(~y_true & y_pred)\n","    fn = np.sum(y_true & ~y_pred)\n","    \n","    epsilon = 1e-7\n","    \n","    precision = tp / (tp + fp + epsilon)\n","    recall = tp / (tp + fn + epsilon)\n","    \n","    f1 = 2 * precision * recall / (precision + recall + epsilon)\n","\n","    return f1 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nv9mxoc7YKjz"},"outputs":[],"source":["#Подгрузим аннотации train\n","with open('data/annotations_val.json') as f:\n","    annotations_test = json.load(f)\n","\n","test_images = annotations_test['images']\n","test_predictions = {}\n","\n","for test_img in tqdm.tqdm_notebook(test_images):\n","    file_name = test_img['file_name']\n","    img_path = os.path.join('data/train_segmentation/images/', file_name)\n","    im = cv2.imread(img_path)\n","    outputs = predictor(im)\n","    prediction = outputs['instances'].pred_masks.cpu().numpy()\n","    # true_preds = []\n","    # thresh = 0.3\n","    # for pred in prediction:\n","    #     pred_area = pred.sum()\n","    #     for was in true_preds:\n","    #         area_intersection = (was[0] * pred).sum()\n","    #         if area_intersection > thresh * was[1] or area_intersection > thresh * pred_area:\n","    #             break\n","    #     else:\n","    #         true_preds.append((pred, pred_area))\n","    # true_preds = np.array([x[0] for x in true_preds])\n","    mask = np.add.reduce(prediction)\n","    mask = mask > 0\n","    print(mask.shape)\n","    test_predictions[file_name] = mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XS5hnBPRDHnL"},"outputs":[],"source":["np.savez_compressed('data/train_segmentation/test_pred.npz',**test_predictions)\n","loaded_train = np.load('data/train_segmentation/binary.npz')\n","loaded_test_pred = np.load('data/train_segmentation/test_pred.npz')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eetWMhmRHNuO"},"outputs":[],"source":["def f1_loss(y_true, y_pred):\n","    tp = np.sum(y_true & y_pred)\n","    tn = np.sum(~y_true & ~y_pred)\n","    fp = np.sum(~y_true & y_pred)\n","    fn = np.sum(y_true & ~y_pred)\n","    \n","    epsilon = 1e-7\n","    \n","    precision = tp / (tp + fp + epsilon)\n","    recall = tp / (tp + fn + epsilon)\n","    \n","    f1 = 2* precision*recall / ( precision + recall + epsilon)\n","    return f1 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kET_6RxrYKj2","scrolled":true},"outputs":[],"source":["f1_scores = []\n","for key in tqdm.tqdm_notebook(loaded_test_pred.files):\n","    pred = loaded_test_pred[key].reshape(-1)\n","    true = loaded_train[key].reshape(-1)\n","    \n","    f1_img = f1_loss(true,pred)\n","    f1_scores.append(f1_img)\n","np.mean(f1_scores)"]},{"cell_type":"markdown","metadata":{"id":"ganj-AzAyecF"},"source":["0.45 - 0.8961"]},{"cell_type":"markdown","metadata":{"id":"FCnHhP_p656M"},"source":["### Making preds for new_images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpvBw9Oe8cZi"},"outputs":[],"source":["test_images = os.listdir('train_segmentation/my_images')\n","def my_show_img(id_image_selected):\n","    example = test_images[id_image_selected]\n","    im = cv2.imread(os.path.join('train_segmentation/my_images', example))\n","    outputs = predictor(im)\n","    plt.figure(figsize=(10, 10), dpi=200)\n","    v = Visualizer(im[:, :],\n","                metadata=val_metadata, \n","                scale=1)\n","    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    plt.imshow(v.get_image()[:, :, ::-1])\n","    # plt.axis('off')\n","    plt.show()\n","    del v\n","    del im\n","    del outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KN8bZ_wu8obt"},"outputs":[],"source":["my_show_img(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WnILDZPgW_UA"},"outputs":[],"source":["#Подгрузим аннотации train\n","test_images = os.listdir('train_segmentation/my_images')\n","test_predictions = {}\n","\n","for i in tqdm.tqdm(range(len(test_images))):\n","    file_name = test_img[i]\n","    img_path = os.path.join('train_segmentation/images/', file_name)\n","    im = cv2.imread(img_path)\n","    outputs = predictor(im)\n","    prediction = outputs['instances'].pred_masks.cpu().numpy()\n","    mask = np.add.reduce(prediction)\n","    mask = mask > 0\n","    test_predictions[file_name] = mask\n","\n","np.savez_compressed('train_segmentation/my_test_pred.npz',**test_predictions)"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"DetectronTraining.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":0}